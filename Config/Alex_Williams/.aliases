# -*-Sh-*- <-- tells emacs what kind of syntax highlighting to use

# ---------------------
# "Unofficial bash strict mode: " #!/bin/bash
# set -euo pipefail
# IFS=$'\n\t'
# ---------------------
if [ -f ${BINF_CORE_WORK_DIR}/Code/alexgw/aliases-server-config ]; then
    source ${BINF_CORE_WORK_DIR}/Code/alexgw/aliases-server-config
elif [ -f ~/.aliases-server-config ]; then
    source ~/.aliases-server-config
fi

if [ -f ~/.local-config-no-git ]; then
    source ~/.local-config-no-git
else
    echo -e "[:HEY:] Since no .local-config-no-git was found, SSH commands, server shortcuts, and tmux coloring may fail. You may want to MANUALLY copy this file over from another machine."
fi

if [[ "${USER}" == "alexgw" ]] || [[ "${USER}" == "awilliams" ]] || [[ "${USER}" == "alexwilliams" ]] || [[ "${USER}" =~ willia* ]]; then
    IS_ALEX_ACCOUNT=1
    ## SAFER 'rm' COMMANDS --only applies to the user(s) above.
    ## Below: aliases the command "rm" to actually run the script "trash.pl," which moves files to a trash directory in /tmp.
    ## They can be recovered by just copying them back.
    ## Use the "checktrash" command to find the trash directory if you forget where it is.
    ## Below: the command to list the top-level contents of the trash directory. You may have to look through the files here if you want to recover something you just accidentally deleted. Beware, files don't last long in /tmp\!
    alias checktrash='mkdir -p /tmp/${USER}/Trash/ && echo -e "Contents of /tmp/${USER}/Trash:" && ls /tmp/${USER}/Trash/'
    alias emptytrash='mkdir -p /tmp/${USER}/Trash/ && /bin/rm -rfv /tmp/${USER}/Trash/ && echo -e "Emptied the trash directory (/tmp/${USER}/Trash)" ;'
    alias rm='trash.pl' ## <-- Note that the "real" rm can still always be invoked by '/bin/rm'
    OUR_RM='trash.pl'
else
    IS_ALEX_ACCOUNT=0
    OUR_RM=rm
fi

echo -e "${a_echo_color}[:FYI:] Loading bash-aliases...${a_end_color}"

CODE_DIRS_FOR_GREPPING="${TIME_FOR_SCIENCE_DIR} ${HOME}/workspace/0_CODE" # <-- Multiple **space-delimited** directories can be here
if [[ -n "${isMac}" ]] ; then ## It *is* a mac!
    function g { ## Searches certain source directories, and the current directory (and any subdirectories!)
	`which grep` --color=always --ignore-case --recursive --extended-regexp --exclude="Mothballed" --exclude=".git" --exclude=".hg" --exclude="CVS" --exclude="[bB]ackup*" \
		     --exclude="*.gsheet" --exclude="*.gdoc" --exclude="*.gslides" --exclude="*.html" --exclude="Annotation*.txt" \
	    "$@" ${CODE_DIRS_FOR_GREPPING} ./
    }
    alias zcat="gzip --decompress --stdout" # The Mac doesn't have the gzip-handling zcat (AKA gzcat)
else
    ## Not a Mac!
    function g {     ## Annoyingly, grep is different between mac/unix
	cmd=(	grep --color=always -T \
	    --ignore-case \
	    --recursive \
	    --extended-regexp \
	    --line-number --with-filename \
	    --exclude-dir="Mothballed" --exclude-dir="\.hg" --exclude-dir="\.git" --exclude-dir="CVS" --exclude-dir="[bB]ackup*" \
	    --binary-files=without-match \
	    --include=*.R --include=*.pl --include=*.pm --include=*.py --include=*.sh --include=*.py
	    --exclude=*.html --exclude=*.gslides --exclude=*.gdoc --exclude=*.gsheet )
	cmd=( "${cmd[@]}" "$@" ${CODE_DIRS_FOR_GREPPING} ) # some weird array format
	"${cmd[@]}" # <- Actually execute. See http://unix.stackexchange.com/questions/131766/why-does-my-shell-script-choke-on-whitespace-or-other-special-characters
    }
fi

function template() {
    if [[ "$#" != 1 ]] ; then echo -e "[:ERR:]] 'template ___' requires EXACTLY ONE file/directory suffix!"; return 1; fi
    EX=$1
    case "${EX}" in 
	[Mm]ak*) SRC=`which template.mak`; DEST="Makefile" ;;
	fishldr*)      SRC="${HOME}/workspace/0_CODE/fishldr_example.cfg.R"        DEST="./C10_fishldr_template.cfg.R" ;;
	[Rr][Mm][Dd]*) SRC="${TIME_FOR_SCIENCE_DIR}/Lab_Code/R/template.Rmd"       DEST="./template.Rmd"        ;;
	[Rr])          SRC="${TIME_FOR_SCIENCE_DIR}/Lab_Code/R/template.R"         DEST="./template.R"          ;;
	py*2)          SRC="${TIME_FOR_SCIENCE_DIR}/Lab_Code/Python/template.py"   DEST="./template_python2.py" ;;
	py*3)          SRC="${TIME_FOR_SCIENCE_DIR}/Lab_Code/Python3/template.py3" DEST="./template_python3.py" ;;
	bash | sh)          SRC="${TIME_FOR_SCIENCE_DIR}/Lab_Code/Shell/template.sh"    DEST="./template.sh" ;;
	*) echo -e "[:ERR:] template did not understand what type of file you requested: the extension you supplied was <${EX}>." ; return 1 ;;
    esac
    if [[ -e "${DEST}" ]]; then
	echo "[:ERR:] Refusing to overwrite the existing file '${DEST}'."
	return 1
    else
	cp -i "${SRC}" "${DEST}"
	echo "[:OK:] Copied a new '${EX}' template to <${DEST}>."
    fi
}

#function maketemplate() {
#    DEST=./Makefile
#    if [[ -e "${DEST}" ]]; then
#	echo "[:ERR:] CANNOT copy a makefile here---there is already one here! Refusing to overwrite it."
#	return 1
#    else
#	echo "[:OK:] Copied a new makefile template to ${DEST}"
#	cp -i `which template.mak` "${DEST}"
#    fi
#
#}
#
#function fishldrtemplate() {
#    DEST=./C10_fishldr_template.cfg.R
#    if [[ -e "${DEST}" ]]; then
#	echo "[:ERR:] CANNOT copy the fishLDR template to this location---there is already one here! Refusing to overwrite it#."
#	return 1
#    else
#	echo "[:OK:] Copied a new fishLDR template to ${DEST}"
#	cp -i "${HOME}/workspace/0_CODE/fishldr_example.cfg.R" "${DEST}"
#    fi
#
#}

function agw_cmd_exists() { # Check if a command exists
    #command -v "$1" &>/dev/null #|| { echo >&2 "I require foo but it's not installed.  Aborting."; exit 1; }
    type "$1" &> /dev/null
    # Alternative approach: command -v "scutil" > /dev/null # <-- Note: we check the exit code from this ("$?") below
    # And then check the exit code:   HAS_PROGRAM=$((1-$?)) # $? = 0 means the above command SUCCEEDED
    # or try: if [[ -n `which exa 2> /dev/null` ]] ... # Usage example: if agw_cmd_exists "exa" && [ "$isMac" == "1" ] ; then ...
    # note that it returns 0 on success, and zero is TRUE in bash!
    # usage: if agw_cmd_exists "command"; then do something; fi
}

function hunt { # cd into a directory with a script
    echo -e "Hunting the most dangerous game of all: cd-ing the directory where \"$(basename $(which $1))\" lives..."
    THEDIR=$(dirname $(which $1 | head -n 1))
    cd "$THEDIR"
    echo -e "Moved into directory <$THEDIR>."
}

function cto { # Like CD, but lets you go to a FILE as well.
    if [[ "$#" != 1 ]] ; then echo -e "[:ERR:]] 'cto' requires EXACTLY ONE file/directory name!"; return 1; fi
    if [[ -d "$1" ]] ; then cd "$1" ; return 0; fi # it's already a directory, change to it!
    cd "$(dirname "$1")"
}

function c() { # Like CD, but lets you go to a FILE as well.
    if [[ "$#" != 1 ]] ; then echo -e "[:ERR:]] 'cto' requires EXACTLY ONE file/directory name!"; return 1; fi
    if [[ -d "$1" ]] ; then cd "$1" ; return 0; fi # it's already a directory, change to it!
    cd "$(dirname "$1")"
}

alias igv='/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/bin/java -jar /Applications/IGV_2.4.10.app/Contents/Java/igv.jar'

function witch() { # Shows the versions for all on-your-path verisons of software.
    # Takes ONE required argument: the program name. Can also take a SECOND argument, which is the actual command to run to check versions (if it isn't 'version')
    # Example:   witch emacs
    #               This works, because 'emacs --version' is how you get the version
    # But for Java, you have to say the following:
    # Or:        witch java -version   (some programs are dumb and do not support --version)
    #               Since the default "--version" doesn't work with Java
    VER_STR=" --version "
    if [[ "$#" == 0 ]]; then
	echo -e "ERR: You need to specify a program to check the versions of. Example:  witch emacs --version ."; return 1;
    fi
    if [[ "$#" == 1 ]] ; then echo -e "witch: Using default '--version' to check for program version..."; fi
    if [[ "$2" != "" ]]; then
	# $2 was actually defined...
	VER_STR="$2"
	#echo -e "ERR: You need to specify a version-obtaining-argument like '--version' to the 'witch' command";
	#echo -e "     Example:   witch emacs --version   or java -version (Java doesn't support --version)";
	#return 1;
    fi
    for f in $(which -a "$1"); do echo -en "\n${a_echo_color}$f${a_end_color} --> "; eval "$f $VER_STR" | head -n 2; done; echo ""
}

function delve() { # or 'dv'
    ## Finds, in any subdirectories, any files that have a name that matches the input text. Sort of like a poor man's "locate"
    find . -iname "*$@*"
}

BRACKET_OPEN='{'
PAREN_OPEN='('
TAB='	'
DLR='\$'
DQ='\"'
BS='\\'
NL="\$'\\n'" # newline!
alias t="transpose.pl"

# Shell navigation/commands

#pushd() { builtin pushd "$@" > /dev/null; } ## <-- make it so that pushd doesn't print the stack every single time

#hasExa=agw_cmd_exists "exa"

#if [[ "$hasExa" && "$isMac" ]]; then # check for 'exa' -- the 'ls' replacement, but only on the Mac---it's slow on Rigel!

#LS_MAX_ENTRIES=200
#alias l2='echo -e "$(exa --color=always)"'

SNEK="\xF0\x9F\x90\x8D"
if agw_cmd_exists "exa" && [ "$isMac" == "1" ] ; then
    # 'exa' is a 'ls' replacement
    function lsw {
	echo -e "${a_banner_color}> >" $(pwd -P) "${a_end_color}"
	if [[ -e ".readme" ]]; then
	    echo -e -n "${a_dirinfo_color}"
	    cat ".readme" | fold -s -w 80 | sed -e "s/^/$(echo -ne ${SNEK})  /"
	    echo -e -n "${a_end_color}"
	    #printf "\xF0\x9F\x90\x8D" # a snake
	fi
	exa --color=auto
    }
    alias ls='exa --color=auto'
    alias ll='exa -l -a --color=auto'
    
elif agw_cmd_exists "exa" ; then
    # Not the mac, but apparently exa is still installed.
    alias ls='exa --color=auto'
    alias ll='exa -l -a --color=auto'
else
    if [[ "$color_prompt" && "$isMac" ]]; then
	AGW_LS_OPT=' -F -G ' #-@ ' ## Mac: Color option is -G. Also, on a Mac, show the extended attributes (-@)
	AGW_LL_COLOR_ALWAYS=${AGW_LS_OPT} # same as above, on the mac
    elif [[ "$color_prompt" && (-z "$isMac") ]]; then
	AGW_LL_COLOR_ALWAYS=' --indicator-style=slash --color=always '
	AGW_LS_OPT=' --indicator-style=slash --color=auto ' ## Ubuntu: color is --color=auto
    else
	AGW_LS_OPT=''
    fi

    if [[ "$isMac" ]]; then
	AGW_MACEXT=' -@ ' # Mac extended attributes
    else
	AGW_MACEXT=' '
    fi

    alias ls="/bin/ls               ${AGW_LS_OPT} "
    function llfunction {
	export CLICOLOR_FORCE=1
	#/bin/ls -l -h -A -F ${AGW_LL_COLOR_ALWAYS} "$@" | perl -pe 's!(.*)!${1} WHAT [:H:]!'
	#LS_ENDCOLOR=$(echo '[0m')
	#|WHATDIR${LS_ENDCOLOR}\/
	/bin/ls -l -h -A -F ${AGW_LL_COLOR_ALWAYS} "$@" | perl -pe "s!(.*)(
P_L_A_C_E__H_O_L_D_E_R
|[.]aliases
|[.]atom.*[/]\$
|[.]bash_history
|[.]bash_logout
|[.]bash_profile
|[.]bashrc
|[.]bash_sessions
|[.]biojs_templates
|[.]cache
|[.]cache
|[.]CFUserTextEncoding\$
|[.]conda.*[/]\$
|[.]condarc
|[.]config
|[.]cups
|[.]dbfseventsd.*[=]\$
|[.]dbus.*[/]\$
|[.]DocumentRevisions-V100.*[/]\$
|[.]dropbox
|[.]DS_Store
|[.]emacs[.]?[d]?
|[.]file\$
|[.]fontconfig.*[/]\$
|[.]fseventsd.*
|[.]gconf.*[/]\$
|[.]gitconfig
|[.]gnome2.*[/]\$
|[.]gnupg
|[.]GSeqWeb.*[/]\$
|igv.*[/]
|[.]inputrc
|[.]InstallAnywhere.*[/]\$
|installer[.]failurerequests
|[.]iterm2.*[/]\$
|[.]ipython.*[/]\$
|[.]iterm2_shell_integration.bash
|[.]jalview_properties
|[.]jenv
|[.]jswingreader
|[.]jupyter.*[/]\$
|[.]kshrc
|[.]lesshst
|[.]local
|[.]lsbatch.*[/]\$
|[.]matplot.*[/]\$
|[.]modules.*->
|[.]modulesbeginenv
|[.]mozilla.*[/]\$
|[.]oracle_jre_usage
|[.]OSInstallerMessages\$
|[.]PKInstallSandboxManager.*[/]\$
|[.]python_history
|[.]pylint.*[/]\$
|[\d\dm|\s][.]R.*[/]\$
|[.]Rhistory.*\$
|Rlib.*[/]
|[\d\dm|\s][.]RData
|[.]rstudio.*[/]\$
|[.]rstudio-desktop
|[.]screenrc
|[.]serverauth
|[.]Spotlight-V100.*[/]\$
|[.]ssh.*[/]
|[\d\dm|\s]Shares.*[/]\$
|[.]subversion
|[.]sqlwork.*[/]\$
|[.]t_coffee
|TimeForScience.*[/]
|[.]tmux[.]conf
|[.]Trash
|[.]UGENE_downloaded.*[/]
|[.]UGENE_files.*[/]
|[.]vamsas
|Velocity_ini[.]txt
|[.]viminfo
|[\d\dm|\s]vc.*[/]
|[.]vol.*/\$
|[.]VolumeIcon.icns
|[.]vscode.*[/]\$
|[.]wget-hsts
|[.]Xauthority
|[.]zoomus
)(.*)\$!\$1\$2\$3\ [:H:]!"xx
	unset CLICOLOR_FORCE
    }
    alias ll=llfunction
    #alias ll="/bin/ls   -l -h -A -F ${AGW_LS_OPT} "
    alias lmac="ll ${AGW_MACEXT} " # mac-specific with EXTENDED attributes (-@)
fi

alias l='ls'
alias lo='ll -r -t' # Depends on "ll" already being defined above. List by TIME so that NEWEST files are at the bottom
alias p='pwd -P'
alias ..='cd ..'
#alias ../='cd ..'
#alias ../../='cd ../../'
#alias ..='pushd ..'
alias res='source ~/.bashrc ; source ~/.bash_profile'
alias mv='mv -i'
alias cp='cp -i'
alias kpk='exit'
alias diffdir='diff -rq' ## diff on directories

# Turn on/off crashplan. No longer necessary.
#alias recrash='sudo launchctl unload /Library/LaunchDaemons/com.crashplan.engine.plist; sleep 1; sudo launchctl load /Library/LaunchDaemons/com.crashplan.engine.plist'

#alias tc='randomize_terminal_color.pl -cycle'
#alias cd='pushd'
#alias b='popd'

## "showoff" makes it so that everyone can a+rx any directories and a+r any files.
## Note that we don't want to make it so everyone can execute *files* necessarily, just folders
## ("Executing" a folder means you can "ls" it and see what's inside.)
function showoff {
    if [ "$#" -eq 0 ]; then echo -e "[:ERR:] Usage: 'showoff' requires path argument(s)! Example: 'showoff ./' for the current directory."; return 1; fi
    for var in "$@"; do echo -e "[:FYI:] showoff is now running 'chmod -R' to allow ANY USER to browse \"$var\""; chmod -R a+rX "$var"; done
}
function sudoshowoff {
    if [ "$#" -eq 0 ]; then echo -e "[:ERR:] Usage: 'sudoshowoff' requires path argument(s)! Example: 'sudoshowoff ./' for the current directory."; return 1; fi
    for var in "$@"; do echo -e "[:FYI:] sudoshowoff: Using sudo chmod -R to allow ANY USER to browse \"$var\""; sudo chmod -R a+rX "$var"; done
}

## Mac-specific commands:
SETFILE_LOCATION=/Applications/Xcode*/Contents/Developer/Tools/SetFile
alias invisible='chflags -h hidden'  #alias invisible='chflags hidden' #$SETFILE_LOCATION -P -a V' ## Mac-only: Make a file/folder invisible to the Finder
alias visible='chflags -h nohidden' #alias visible='chflags nohidden' #$SETFILE_LOCATION -P -a v' ## Mac-only: opposite of "invisible"
alias lock='chflags uchg'     # Mac: lock file
alias unlock='chflags nouchg' # Mac: unlock file

alias clearicon='$SETFILE_LOCATION -P -a c' ## clear mac custom icons. Useful for images that have old custom icons.
alias version="lsb_release -a" # Tells you which version of Ubuntu you are running!

function mac2unix { # Convert a Mac-style line-ending file to a UNIX one. Useful for when you save a file in Excel and then UNIX won't read it.
    if [[ -f "$1" ]] ; then cat "$1" | tr '\r' '\n' ## if a filename is passed in, then auto-cat that file
    else tr '\r' '\n' ; fi ## otherwise it's probably part of a cmdline pipe
}

function dos2unix { # Convert a Windows-style line-ending file to a UNIX one. Useful for when you save a file in Excel and then UNIX won't read it.
    if [[ -f "$1" ]] ; then cat "$1" | tr -d '\r' ## if a filename is passed in, then auto-cat that file
    else tr -d '\r'; fi ## otherwise it's probably part of a cmdline pipe
}

## Utility commands

if [[ -f ~/.agw_cfg/prefer_screen ]]; then
    echo -e "[:FYI:] Preferring SCREEN over tmux: aliasing 'rr' to screen."
    alias rr='screen -xR -U' #"screen -xR -U" ## Reconnect to the previous screen, or make a new one if there isn't one already
    ## -U: "screen understands UTF8"
else
    alias rr='tmux attach || tmux new' #"screen -xR -U" ## Reconnect to the previous screen, or make a new one if there isn't one already
fi

alias wcl='grep -c ""' # actually gives you the NUMBER and not the filename
alias sortt='sort -t "	"' # sort with tab as separator
alias sortg='sort -g -t "	"' # sort NUMBERS, with tab as separator

#if [[ -f /usr/local/bin/emacs ]]; then
#if [[ -n "$isMac" ]]; then
#    alias e='emacs --no-splash -nw ' # use 'brew install emacs' to update emacs
#else
alias e="emacsclient -nw  -c --alternate-editor=\"\"" # "As a special exception, if command is the empty string, then emacsclient starts Emacs in daemon mode (as emacs --daemon) and then tries connecting again."
#alias e2="LANG='en_US.UTF-8' bash -c 'emacsclient -nw  -c --alternate-editor=\"\"'" # "As a special exception, if command is the empty string, then emacsclient starts Emacs in daemon mode (as emacs --daemon) and then tries connecting again."
#fi

#alias t='transpose.pl -q'
alias tattle="echo -e -n '$a_status_color'; ps aux | tail -n +2 | sort --reverse -k 3,3 | head -n 5 | perl -p -e 's/[ ]+/\t/g' | cut -f 1,3,4,11 | cap.pl 'USER,CPU,MEM,TASK' | sheet.pl --color=always \
--ht=75 --trunc=60 | tail -n +2 ; echo -e -n '$a_end_color'"

# GNU Make-related
alias make='make --warn-undefined-variables --print-directory'
alias mcm='make clean && make'
function remake { ## Lets you type "remake" to remove a file and then use GNU make to try to re-generate it
    ${OUR_RM} "$@" ; make --warn-undefined-variables --print-directory "$@"
}

function rel { ## Remake and then view
    ${OUR_RM} "$@" ; make --warn-undefined-variables --print-directory "$@" ; s "$@"
}

# Aliases related to COLOR GREP
alias grepi='grep   -i' # <-- runs fast if "LANG=C" is the specified language
alias grepc='grep   --color=always --with-filename --line-number'
alias egrepc='egrep --color=always --with-filename --line-number'
alias fgrepc='fgrep --color=always --with-filename --line-number'

# git aliases
alias gitcom="git commit -a -m 'Changes committed by ${USER}'"
alias gitlist="git ls-tree -r master --name-only" # show currently tracked files
alias gits="git status"
alias gitstat="git ls-files --modified --deleted"
alias gitdiff="git difftool"

function googcom {
    D="/Volumes/GoogleDrive/My Drive/Alex_All_Projects"
    cd "/Volumes/GoogleDrive/My Drive/Alex_All_Projects"
    echo "Changed directories to: ${D}"
    gitcom
}

function sciencecom {
    # If you want to NOT interact remotely (for example, this is the 'most upstream' repo with nothing to push to) then pass in NO_REMOTE as argument 2.
    if [[ -f ~/.ssh/id_rsa_timeforscience ]]; then ssh-add ~/.ssh/id_rsa_timeforscience; fi
    if [[ ! -d "$1/.git" ]] ; then echo -e "[:HEY:] No $1 git repository exists on this machine."; return 1; fi
    if [[ "${2}" == "NO_REMOTE" ]]; then SHOULD_REMOTE=0; else SHOULD_REMOTE=1; fi
    #echo -e "[:FYI:] Committing GIT changes locally."
    git --git-dir="$1/.git" --work-tree="$1" commit -a -m "Committing changes from ${USER}"
    if [[ "${SHOULD_REMOTE}" == 1 ]]; then
	#echo "Should remote COMMIT --> YES PLEASE ${SHOULD_REMOTE}"
	echo -e "Pushing GIT changes to remote master."
	git --git-dir="$1/.git" --work-tree="$1" push origin master ;
    fi
}

function scienceup {
    # If you want to NOT interact remotely (for example, this is the 'most upstream' repo with nothing to pull from) then pass in NO_REMOTE as argument 2.
    if [[ ! -d "$1/.git" ]] ; then echo -e "[:HEY:] No $1 git repository exists on this machine."; return 1; fi
    if [[ "${2}" == "NO_REMOTE" ]]; then SHOULD_REMOTE=0; else SHOULD_REMOTE=1; fi
    #echo "Should remote --> ${SHOULD_REMOTE}"
    echo -e "[:FYI:] Committing any local GIT changes before syncing with remote master."
    git --git-dir="$1/.git" --work-tree="$1" commit -a -m "Committing any local changes from ${USER} before sync with remote server." ;
    if [[ "${SHOULD_REMOTE}" == 1 ]]; then
	#echo "Should remote pull --> YES PLEASE ${SHOULD_REMOTE}"
	echo -e "[:FYI:] Pulling GIT changes from remote master."
	git --git-dir="$1/.git" --work-tree="$1" pull ;
    fi
}

function scienceboth() {
    if [[ -d "$1" ]]; then
	echo -e "${REVERSE}$1:${a_end_color}"; scienceup "$@" && sciencecom "$@"
    fi

}
function science() {
    # Manually copy a bunch of GOOGLE CODE controlled files
    GD="${HOME}/GOOG/Alex_All_Projects"
    WSPRE="${HOME}/workspace/0_CODE"
    scienceboth "${HOME}/workspace/0_CODE" # sync these files before overwriting the local W_...Rmd ones
    #if [[ -d "${GD}" ]]; then
#	[[ -d "${WSPRE}" ]] || { echo "Failure! Missing expected directory: ${WSPRE}"; return 99; }
#	#find . -iname "W_*.Rmd" -o -iname "W_*.R"
#	for f in "${GD}"/[123][0-9][0-9][0-9]**/W_*.{Rmd,mak,R}; do
#	    echo "[:OK:] Copying some source files from Google Drive to the local git repo. We would prefer to symlink these, but that is impossible since Google Drive does not support symlinks."
#	    g=$(basename ${f}); h="${WSPRE}/${g/W_}"; echo "[:OK:] ${f} --> ${h}...";
#	    \rsync -avz "${f}" "${h}"
#	done
#    fi
    #WEBO="${HOME}/web"
    #
    #if [[ -d "${WEBO}" && -d "${WSPRE}" ]]; then
#	echo "[:OK:] Rsyncing web files to a GIT directory..."
#	\rsync -avz ${WEBO}/index.html ${WSPRE}/web/
#	#\rsync -avz ${WEBO}/projects/*.html ${WSPRE}/web/projects/
#    fi
    # ================== Done with this Google code stuff ==============
    scienceboth "${TIME_FOR_SCIENCE_DIR}"
    #scienceboth "${HOME}/workspace/git_0_CODE"
    #scienceboth "${HOME}/workspace/0_CODE" # Sync AGAIN after copying
}

AGW_SSH_OPTIONS=" -o ServerAliveInterval=30 -C "

function rmd {
    if [[ "$#" != 1 ]]; then echo -e "[:ERR:] the 'rmd'-ify command needs exactly one filename argument."; return 1; fi
    FILE_TO_RENDER=$1
    if [[ ! ${FILE_TO_RENDER} =~ .*Rmd ]]; then echo -e "[:ERR:] Your file to render, <${FILE_TO_RENDER}>, did not end in '.Rmd'!!"; return 1; fi
    if [[ ! -f "${FILE_TO_RENDER}" ]]    ; then echo -e "[:ERR:] Your file to render, <${FILE_TO_RENDER}>, did not appear to exist!"; return 1; fi
    NON_SYMLINKED="${FILE_TO_RENDER}.alias.tmp.Rmd" # R markdown handles aliases in a super annoying fashion
    if [[ ! -f "${NON_SYMLINKED}" ]]    ; then echo -e "[:ERR:] We could not copy the file to a non-symlinked location!"; return 1; fi
    WORKDIR=`dirname ${FILE_TO_RENDER}`
    \cp -f --dereference "${FILE_TO_RENDER}" "${NON_SYMLINKED}"
    rmd_cmd="Rscript -e 'library(rmarkdown); rmarkdown::render(\"${NON_SYMLINKED}\", output_dir=\"${WORKDIR}\", knit_root_dir=\"${WORKDIR}\");'  "
    echo "[:OK:] Running this command: " ${rmd_cmd}
    eval ${rmd_cmd}
    \rm "${NON_SYMLINKED}"
}

alias agwcom='ssh ${AGW_SSH_OPTIONS}   ${AGWCOM_USERNAME}@${AGWCOM_URL}'

alias nami=' ssh ${AGW_SSH_OPTIONS} -i ~/Dropbox/metaquery-dev.pem bitnami@52.53.252.164'
alias rig=' ssh ${AGW_SSH_OPTIONS}     ${ACC_U}@${RIG_IP}'
RIG_SAND_IP=${RIG_IP/./-sandbox.} # add "-sandbox" before the first dot

## LESS +++++++++++++++++
export PAGER=less
[[ -x /usr/bin/lesspipe ]] && eval "$(SHELL=/bin/sh lesspipe)" # make "less" friendly for non-text input files
export LESSOPEN="|${TIME_FOR_SCIENCE_DIR}/Config/1_Shell_Config/lesspipe_basic.sh %s"
# lesspipe_basic.sh casues less to transparently decompress gzipped files before showing them. Old:  '|/usr/bin/lesspipe.sh %s'
alias magicless='env LESSOPEN="|${TIME_FOR_SCIENCE_DIR}/Config/1_Shell_Config/lesspipe_advanced.sh %s" /usr/bin/less -S --RAW-CONTROL-CHARS -f --IGNORE-CASE'
# It's less, but it "magically" handles gzipped files and automatically runs ".tab" files through sheet.pl
# Note that this only magically happens if the files are passed in on the command line--otherwise you have
# to use "ssf" to force sheet.pl to be run (if a file is passed through a pipe, then it won't be run through
# sheet.pl unless you say "cat something | ssf"
## LESS +++++++++++++++++

# Plain "sn" doesn't run anything through sheet.pl, but it *does* handle gzipped files
alias sn="/usr/bin/less -S --LINE-NUMBERS --status-column --RAW-CONTROL-CHARS -f --IGNORE-CASE"
alias sweep="${OUR_RM} *.tmp *.temp" ## Sweep out the .tmp files
alias htop="htop --sort-key PERCENT_CPU"

#function playnicely {
#    # Takes one argument.
#    # requires sudo privileges. Takes one argument, the username to make play nicely:
#    # example: playnicely THEUSERNAME
#    SSS=$(ps -fu "$1" | perl -pe 's/[ ]+/\t/g' | cut -f 2 | tail -n +2);
#    for pid in $SSS ; do echo 'ionice-ing and nice+15-ing process ID' $pid; sudo ionice -c3 -p $pid ; sudo renice +15 -p $pid ; done 
#}
#
#function disknicely {
#    # Takes ZERO arguments. Just for making the 'nfsd' processes less annoying.
#    SSS=$(ps -eopid,uid,cmd | grep "nfsd" | grep -v "grep" | perl -p -e "s/^[ ]+//" | cut -d " " -f 1) # Get any 'nfsd' processes
#    for pid in $SSS ; do echo 'ionice-ing and nice+15-ing the NFS process ID' $pid; sudo ionice -c3 -p $pid ; sudo renice +15 -p $pid ; don#e 
#}

function s() { ## <-- this needs to come BEFORE the other things that use less!
    magicless --LINE-NUMBERS --status-column "$@"  # "s" uses "magicless" to run files through sheet.pl
}

function acol() {
    column -s $'\t' -t # columns delimited by tabs! Like 'sheet.py'
}

function acols() {
    s "$@" | acol | s # Pipe it through magicless, then 'acol', then magicless AGAIN. Like a poor man's sheet.py (way faster, though)
}

function sf() {
    # Forces sheet.pl to be called ("SS Force sheet.pl").  Can only view ONE file, unlike "ss"
    /usr/bin/less --RAW-CONTROL-CHARS "$1" | sheet.pl --color=always | s
}

function s1() {
    # like sf, but shorter columns # Can only view ONE file, unlike "s"
    /usr/bin/less --RAW-CONTROL-CHARS "$1" | sheet.pl --color=always --trunc=15 | s
}

function s2() {
    # like sf, but shorter columns # Can only view ONE file, unlike "s"
    /usr/bin/less --RAW-CONTROL-CHARS "$1" | sheet.pl --color=always --trunc=25 | s
}

function v() {
    # Use sheet.py to view a file or list of files. These files cannot be gzipped, however.
    # Must be python2.6, and not python 3, currently
    `which sheet.py` "$@"
}

alias huh='cat <(declare -f) <(alias)' ## uses bash subshells to show everything that is defined
#alias backoff='${TIME_FOR_SCIENCE_DIR}/Config/Alex_Williams/unix_scripts/crashplan-backup-mod.sudo.sh off'
#alias backon='${TIME_FOR_SCIENCE_DIR}/Config/Alex_Williams/unix_scripts/crashplan-backup-mod.sudo.sh on'

function n() { # show colors
    # ${cpre} is defined in my ~/.bashrc (usually as \033)
    echo -e  "${cpre}[30m black ${cpre}[31mred ${cpre}[32mgreen ${cpre}[33myellow ${cpre}[34mblue ${cpre}[35mmagenta ${cpre}[36mcyan ${cpre}[37mwhite"
}

## Maczip zips things on the mac WITHOUT including the dot files and .DS_Stores
function maczip() {
    if [[ "$#" == 1 ]] ; then theCompressedBasename="$1"; ## If you pass it one argument, then that argument will also be the filename
    else theCompressedBasename="Archive_zipped_without_Mac_files";
    fi
    theCompressedBasename=`echo "$theCompressedBasename" | sed "s/[/]//"` ## Let's remove any slashes from the name of the *output*. That way if someone types "mini MyDir/" it will generate "MyDir.zip" and NOT "MyDir/.zip"
    if [[ -f "${theCompressedBasename}.zip" ]] ; then
	echo -e "[:ERR:] mini: HALTING: Cannot create a new archive---perhaps ${theCompressedBasename}.zip already exists.\nThis is forbidden--you cannot create the archive to overwrite the current archive!!! Delete it and compress again." ;
	return 1;
    else
	if [[ "$#" -gt 1 ]] ; then echo -e "[:FYI:] Adding a total of $# files to the new zip archive, which OMITS Mac-specific files (e.g. .DS_Store)." ; fi
	for var in "$@"; do echo -e "[:FYI:] * Archiving $var --> ${theCompressedBasename}.zip" ; done
	echo -e "[:FYI:] ZIP command running now..." ;
	zip -9 -r -X --symlinks --exclude "*.DS_Store" --exclude="*~" --exclude="\$*" "${theCompressedBasename}.zip"  $@;
	echo -e "[:FYI:] Compression complete." ;
    fi
}

function xztar() {
    # Tar and xzip in one place so you don't have to remember the syntax. Or you could just remember the syntax!
    #if [[ "$#" != 1 ]]; then echo -e "[:ERR:] xztar can only accept ONE argument! One directory or file to tar/xz."; return 1; fi
    F_TAR=$(basename $1).tar
    F_TAR_XZ=$(basename $1).tar.xz
    echo -e "Note that xz is slow! So be prepared for it to take forever. Creating this archive: ${F_TAR_XZ}"
    tar -cvf "${F_TAR}" "$@"
    time xz --threads=0 -9 "${F_TAR}"
}

## Mini is a function that creates a .bz2 archive of whatever you pass into it.
## It works in a manner similar to right-clicking and zipping a file on the Mac.
## If you just pass it in ONE file named FILE, then the output filename is "FILE.tar.bz2" .
## If you give it multiple files, the output is in Archive.tar.gz
## To extract a "mini" archive, use "unmini" .
# Bugs: it ONLY WORKS IN THE CURRENT DIRECTORY! And it probably hates whitespaces.
# maybe this will help with escaping? for f in `ls`; do printf "%q " $f; done
# looks like 'printf' can save the day
function mini() {
    [[ "$#" == 1 ]]         && comp_base="$1" || comp_base="Archive" ## If you pass it one argument, then that argument will also be the filename
    agw_cmd_exists "ionice" && AGW_IONICE="ionice -c3" || AGW_IONICE="" # ionice doesn't exist on BSD/Mac, so check for it
    # xz is 10 times slower than bz2 to compress, but can be ~30% smaller for text.
    # xz is FASTER to decompress than bzip2, and is nearly the same as gzip.
    comp_base=`echo "${comp_base}" | sed "s/[/]//g"` ## Let's remove any slashes from the name of the *output*. That way if someone types "mini MyDir/" it will generate "MyDir.tar.bz2" and NOT "MyDir/.tar.bz2"
    if [[ $(tar --version) =~ .*bsdtar.* ]]; then TAREX=" -c -v "      # BSD tar
    else TAREX=" --preserve-permissions --atime-preserve -c -v "; fi   # GNU tar
    if [[ -f "${comp_base}.tar" || -f "${comp_base}.tar.bz2" ]] ; then
	echo -e "mini: HALTING: Cannot create a new archive---either ${comp_base}.tar or ${comp_base}.tar.bz2 already exists.\nThis is forbidden--you cannot create the archive to overwrite the current archive!!! Delete it and compress again." ;
	return 1;
    else
	if [[ "$#" -gt 1 ]] ; then echo -e "Adding a total of $# files to the archive." ; fi
	for var in "$@"; do echo -e " * Archiving $var --> ${comp_base}.tar.bz2" ; done
	echo -e "[TAR] command running now... maybe should use 'xz' instead of bzip" ;
	eval "$AGW_IONICE" tar "$TAREX" --bzip2 -f "${comp_base}.tar.bz2" $@;
	echo -e "[Done]" ;
    fi
}

## Extracts any number of compressed files of ANY type. Usage: 'unmini a.bz2 b.tar.gz c.tar.bz2 ... etc...'
function unmini() {
    agw_cmd_exists "ionice" && AGW_IONICE="ionice -c3" || AGW_IONICE="" # ionice doesn't exist on BSD/Mac, so check for it
    if [[ $(tar --version) =~ .*bsdtar.* ]]; then TARPARAM=" -x -v "                 # BSD tar
    else TARPARAM=" --preserve-permissions --atime-preserve --keep-old-files -x -v "; fi # GNU tar
    NEVER_OVERWRITE_ZIP=" -n "
    for fff in "$@"; do # Loop through all the input arguments
	echo -e "[:FYI:] * Decompressing \"${fff}\"..."
	case "${fff}" in 
	    *.tar.gz)  EX_CMD="tar ${TARPARAM} --ungzip -f  $fff" ;; 
	    *.tar.bz2) EX_CMD="tar ${TARPARAM}  --bzip2 -f  $fff" ;;
	    *.tar.xz)  EX_CMD="tar ${TARPARAM}     --xz -f  $fff" ;; 
	    *.tar)     EX_CMD="tar ${TARPARAM}          -f  $fff" ;;
	    *.xz)      EX_CMD="xz    --decompress         $fff" ;; 
	    *.gz)      EX_CMD="gzip  --decompress         $fff" ;; 
	    *.bz2)     EX_CMD="bzip2 --decompress         $fff" ;;
	    *.zip)     EX_CMD="unzip ${NEVER_OVERWRITE_ZIP} $fff   -d ${fff/.zip/}" ;;
	    *) echo -e "[:ERR:] unmini has failed to detect type of archive (filename is <${fff}>. Recommendation: make sure that file exists)... aborting." ; return 1 ;;
	esac
	eval "${AGW_IONICE}" "${EX_CMD}" # <-- actually decompress the file
    done
}

alias snake="echo -n $'\xF0\x9F\x90\x8D'' '"  # Emoji snake. See http://apps.timwhitlock.info/emoji/tables/unicode
alias cake="echo  -n $'\xF0\x9F\x8D\xB0'' '"  # Emoji cake.  See http://apps.timwhitlock.info/emoji/tables/unicode

function qkiri() { # kill all your OWN jobs
    echo -e "[:FYI:] If qkiri fails, try running this command: qselect -u YOURNAME | sudo xargs qdel -p"
    echo -e "[:HEY:] REALLY terminate LITERALLY EVERY SINGLE ONE OF YOUR JOBS? ***ALL*** OF THEM???"
    select yn in "[:FYI:] Wait a minute! Keep these jobs!" "[:ERR:] DELETE THEM WITHOUT REMORSE!!"; do
	case $yn in
	    Wrong*)  echo -e "Ok, not doing anything."; break;;
	    Delete*) bkill 0 -u ${USER}
	esac
    done
    #qselect -u ${USER} | xargs qdel ; echo -e "[Cancelled jobs]"; sleep 1; qstats; break ;;
}

# grep 'pattern' can also be replaced with: perl -nle "print if m{PATTERN}" # <-- beware of '$1' versus "$1" issues!
function qstatlong() { # show qstat with LONG (full) job names:
    qstat -f | egrep -i '(Job Id|Job_Name|Job_Owner|job_state|list.walltime)' | perl -pe 's/(.*Job_Owner.*)@.*/\1/i' | perl -pe 's/.*=\s//' | perl -pe 's/\n/\t/g' | perl -pe 's/(Job Id:\s|$)/\n/ig' | grep -v '^$'
}

function qsass() { # kill all jobs that match this grep... works for usernames, jobs, etc. Be careful!
    # Example usage:  qsass    yourname             # Hopefully yourname is not a subset of someone ELSE's name!
    # or:             qsass    test_job_number_     # Uses GREP, so watch out for invalid regexps!
    #sudo echo 'Initializing sudo permissions here'
    if [[ ${#1} -lt 4 ]]; then
	echo -e "ERR: Your argument to qsass ($1) was not long enough (it is only length ${#1})---it needs to be at least 4 characters, or else we don't believe it's a valid input! Be careful! Even PARTIAL MATCHES will trigger the job deletion. So don't delete 'bad_job' if you don't also want to delete 'not_a_bad_job'."
	return 1;
    fi;
    echo -e "Trying to use qdel to delete jobs that match '$1'...";
    IFS=$'\n' # <-- split a bash string on NEWLINES and not spaces!
    DELETE_US=()
    for jobtext in $(qstatlong | perl -nle "print if m{$1}"); do
	jobid=$(echo -e "$jobtext" | cut -d '.' -f 1)
	echo -e "Found a job ID to delete that matched '$1': $jobid (\"$jobtext\")";
	DELETE_US+=("$jobid")
    done
    echo -e "If you really want to DELETE those jobs, input a '2'."
    select yn in "Wrong! Keep these jobs!" "Delete these jobs from the queue!"; do
	case $yn in
	    Wrong*)  echo -e "Cancelled!"; break;;
	    Delete*) for j in "${DELETE_US[@]}"; do echo -e "Deleting job ID $j..."; `which qdel` $j ; done; break;;
	esac
    done
}

function mvln() { # move and then make an ALIAS in the current location, leaving a "ghostly" alias where the file previously was
    if [[ "$#"  < 2 ]] ; then echo -e "[:ERR:] You need to pass AT LEAST ONE filename (source) and ONE DESTINATION (probably a directory?) into this function!"; return 1; fi
    if [[ "$#" != 2 ]] ; then echo -e "[:ERR:] Right now, this only works with TWO ARGUMENTS (target and destination)!"; return 1; fi
    SOURCE=$1
    if [[ ! -e "${SOURCE}" ]] ; then echo -e "[:ERR:] Your source file (${SOURCE}) does not exist!"; return 1; fi
    DEST=${@: -1}
    if [[ -d "${DEST}" ]]; then # target is a directory
	DEST="${DEST%/}/${SOURCE}" # remove trailing slash. This is OK even with '/' (root), since we always insert a slash at the end no matter what
    fi
    mv "${SOURCE}" "${DEST}"  && ln -s "${DEST}" "${SOURCE}" && echo -e "Moved ${a_green}${SOURCE} ${a_yellow}-> ${a_green}${DEST}${a_end_color} and left a symlink at ${a_cyan}${SOURCE}${a_end_color}"
    if [[ $? != 0 ]]; then
	echo -e "[:ERR:] Google Drive (or whatever the filesystem is that is complaining about symlinks) does NOT support cross-filesystem symlinks, so although we did successfully MOVE your file, we were unable to create a symlink. Your file was moved to this location --> ${DEST} "
	return 1;
    fi
}

#function neararchive() { # usage: cd /work/projects/your-project  then: "neararchive myproj-1234-rna-mouse"  --> will move things to the nearline storage and symlink them back
#    if [[ "$#" == 0 ]] ; then echo -e "[:ERR:] You need to pass AT LEAST ONE filename into this function!"; return 1; fi
#    D=$(basename `pwd`)
#    TARGET="/nearline_storage/castles_made_of_sand/not_backed_up/${D}"
#    echo -e "We would like to move the following $# files to the NEARLINE SECONDARY STORAGE folder <${TARGET}/>... sound ok to you? Select a NUMERIC option below:"
#    ls -1 -lh $@
#    select yn in "[Cancel]" "Move those files!"; do
#	case $yn in
#	    Move*) mkdir -p "$TARGET"; for f in "$@"; do mv "$f" "${TARGET}/" && ln -s "${TARGET}/$f" ./ ; echo -e "Moved <$f> to <${TARGET}/$f>..." ; done; break;;
#	    *) echo -e "Ok, not doing anything."; break;;
#	esac
#    done
#}

function accuse() { # See who is using the CPU. Usage: just "accuse" with no arguments
    USERS_WITH_JOBS=$(ps aux | tail -n +2 | cut -d ' ' -f 1 | uniq | sort -u)
    echo -e ">> Let's see who is using the CPU..."              >&2 # print to stderr
    echo -e ">> Going to check these users: ${USERS_WITH_JOBS}" >&2 # print to stderr
    TOPTEMP=$(mktemp) # Make a temp file
    TEMP2=$(mktemp)   # Make another temp file
    D=$(date '+%F %H:%M:%S')
    top -b -n 1 | tail -n +7 >> ${TOPTEMP} ;
    echo -e "USERNAME\t%CPU\tBARGRAPH\t# Date = \"${D}\"" >> ${TEMP2}
    NCPU=$(nproc)
    for u in ${USERS_WITH_JOBS}; do \
	cat $TOPTEMP | perl -e "my \$user = ${u}; my \$tot = 0; while(<>){ chomp; my @a=split(/\s+/); if (\$a[2] =~ m/${u}/i) {\$tot += \$a[9];}; } my \$stars = '|' . 'x' x (1+int((\$tot+50)/${NCPU})); print qq{\$user\t\$tot\t\$stars\n};"  >> ${TEMP2}; \
    done ;
    cat ${TEMP2} | column -t -s $'\t'
    /bin/rm ${TOPTEMP} ${TEMP2}
}

function giant() { # find giant files
    #SAVED_IFS=$IFS; IFS=$(echo -en "\n\b")
    echo -e "Calculating all sizes first, then sorting them in ascending order..." >&2 # print to stderr
    DIRS="$@"
    sudo du -sc $DIRS | perl -nle 'print if not m/\btotal\b/' | perl -nle "@a = split(/\s+/); if (\$a[0]>0){print ((\$a[0]/1024.0/1024.0).qq{\t}.\$a[1]);} else { };" | sort -k1,1g | perl -e "my \$t = 0; while(<>) { my @a=split; \$t += \$a[0]; print join(qq{\t}, int(\$t/1024.0).qq{T}, int(\$a[0]).qq{G}, \$a[1]).qq{\n} }"
    #IFS=$SAVED_IFS
}

function giantpleb() { # find giant files
    #SAVED_IFS=$IFS; IFS=$(echo -en "\n\b")
    echo -e "Calculating all sizes first, then sorting them in ascending order..." >&2 # print to stderr
    DIRS="$@"
    du -sc $DIRS | perl -nle 'print if not m/\btotal\b/' | perl -nle "@a = split(/\s+/); if (\$a[0]>0){print ((\$a[0]/1024.0/1024.0).qq{\t}.\$a[1]);} else { };" | sort -k1,1g | perl -e "my \$t = 0; while(<>) { my @a=split; \$t += \$a[0]; print join(qq{\t}, int(\$t/1024.0).qq{T}, int(\$a[0]).qq{G}, \$a[1]).qq{\n} }"
    #IFS=$SAVED_IFS
}

function wholog() {
    echo -e "About to show who logs in and how big their home directories are..." >&2 # print to stderr
    TMP=$(mktemp)
    for f in $(cat /etc/passwd | cut -d ':' -f 1); do echo -e "Checking $f..." >&2 ; sudo lastlog -u $f; done | grep -v '^Username' | perl -pe 's/\s+/\t/' > $TMP
    sudo du -sch /home/* | perl -pe 's/\/home\///' | join.pl -o "NO_HOMEDIR" -1 1 -2 2 $TMP - | column -t -s $'\t'
}

function qing() {
    echo -e "'qing' is 'qstats' but only showing NON-COMPLETED jobs..."
    echo -e "Note that 'qstat -f' may fail in cases where 'qstat' does not. Try plain 'qstat' if this command seems to be taking forever."
    echo -e "'qstat -f' has been known to take upwards of 2 minutes to run."
    qstats | grep -v ' COMPLETE '
    qstat -f -Q
}

function mypip() {
    if [[ "$#" == 0 ]] ; then echo -e "[:ERR:] You need to pass AT LEAST ONE PYTHON package-to-install into this function!"; return 1; fi
    echo -e "Installing the following python libraries: $@"
    echo -e "Installing into 'BINFPYROOT' environment variable at: $BINFPYROOT"
    pip2.7 install --ignore-installed --install-option="--prefix=$BINFPYROOT" $@
}

function mypylint() {
    if [[ "$#" == 0 ]] ; then echo -e "[:ERR:] You need to pass AT LEAST ONE PYTHON filename into this function!"; return 1; fi
    echo -e "Lintifying this file... $FILE"
    DISABLE_THESE_CHECKS="locally-disabled,global-variable-not-assigned,line-too-long,superfluous-parens,bad-whitespace,unused-wildcard-import,trailing-whitespace,unnecessary-pass,missing-docstring,invalid-name,global-statement,multiple-statements,too-many-locals,too-many-statements,too-many-branches,too-few-public-methods,too-many-lines,too-many-instance-attributes,too-many-arguments,wildcard-import,bad-continuation,unidiomatic-typecheck,expression-not-assigned,deprecated-lambda"
    pylint --jobs=4 --output-format=colorized --disable=$DISABLE_THESE_CHECKS "$@"
    # Best usage is: mypylint | s for viewing the colorized output!
}

function mycat() { # cat2 / mycat
    # basically like 'cat' or 'zcat' but fancier
    # Based on file extension, turns something into plain text! Works on mixed files. Only delves one level of compression deep.
    for filename in "$@"; do # Loop through all the input arguments. Doesn't work with redirection.
	VC="cat" # This is the default
	filetype=$(file --dereference --brief "$filename")
	case "$filename" in
	    *.bam)  VC="samtools view -h " ; filetype="BAM_FILE_DETECTED_AGW";;
	esac
	case "$filetype" in 
	    gzip*)     VC="gzip --decompress --stdout " ;; # zcat / gzcat on the Mac
	    bzip2*)   VC="bzip2 --decompress --stdout " ;; # bzcat
	    [xX][zZ]*)   VC="xz --decompress --stdout " ;; # xzcat
	esac
	${VC} "$filename" # <-- actually decompress the file and print it to stdout
    done
}

alias tab="column -t -s $'\t'"

function brutallycompress() {
    # Usage:    brutallycompress  DIRECTORY1   DIRECTORY2   DIRECTORY3
    # Recursively goes through and compresses (with gzip) any files with the extensions listed below.
    if [[ "$#" == 0 ]] ; then echo -e "[:ERR:] in arguments to brutallycompress] You need to pass AT LEAST ONE target directory into this function--it can also be '.' for the current directory!"; return 1; fi
    RESTRING=".*[._]\(wig\|bed\|_tracking\|diff\|bed.count\|moa\|fa\|fasta\|fq\|fastq\|txt\|csv\|tab\)"
    echo -e "# About to compress ($COMPRESS)\n#     anything in the following locations: $@\n#     that matches this REGULAR EXPRESSION: $RESTRING"
    echo -e "# -----------------------------------------------------------------------------------------------"
    for location in "$@"; do # Sanity check to make sure all inputs are DIRECTORIES to start
	if [[ ! -d "$location" ]] ; then echo -e "[:ERR:] in arguments to brutallycompress]: input '$location' was not a directory. Fix this--only give DIRECTORIES to 'brutallycompress'. Use '.' (not '*') if you want everything in the current directory!"; return 1; fi
    done
    for location in "$@"; do # Loop through all the input arguments. Doesn't work with redirection.
	if [[ ! -d "$location" ]] ; then echo -e "[:ERR:]: input '$location' was not a directory!"; return 1; fi
	find "$location" -type f -regex "$RESTRING" -print0 | xargs -0 -I {} sh -c "echo 'Compressing' '{}'; gzip --verbose -6 '{}';" # <-- do **NOT** put double quotes around $COMPRESS (no "")
	#find "$location" -type f \( -iname "*.bed" -o -iname "*_tracking" -o -iname "*.diff" -o -iname "*.bed.count" -o -iname "*.moa" -o -iname "*.fa" -o -iname "*.fq" -o -iname "*.fasta" -o -iname "*.fastq" -o -iname "*.txt" \) -print0 | xargs -0 $COMPRESS
    done #  xargs -I %%% sh -c 'echo %%%; echo %%%;'
}

function rtag() {
    # Recursively set finder tags
    tag=$1
    shift
    for fff in "$@"; do # Loop through all the input arguments. Doesn't work with redirection.
	#find . -exec tag --add tagname {} \;  -print
	#find $name -type f | xargs xattr -wx com.apple.FinderInfo "`xattr -px sampleFile`"
	echo -e "Adding tag $tag to $fff"
    done
}

function wgetdevour() { # Downloads certain types of files via wget for a password-protected directory
    if [[ "$#" != "3" ]] ; then echo -e "[:ERR:] You need to pass THREE arguments -- username, password, directory!"; return 1; fi
    USERNAME=$1
    PASSWORD=$2
    DIRECTORY=$3
    wget -mk -r -U mozilla --connect-timeout=90 --random-wait -e robots=off --limit-rate=1m --tries=99 --timeout=50 \
	 -A md5,fasta,fa,fastq,fq,bz2,gz,Z,gzip,bzip2,pdf,xls,xlsx,bed,sam,bam,vcf,csv,txt,sh,complete \
	 --no-parent \
	 --http-user="$USERNAME" --http-passwd="$PASSWORD" "$DIRECTORY/" # trailing slash here is crucial
}


function hist() {
    history | tail -n 100
}

QUEUE_LOGFILE_PATTERN='.*.\([eo][0-9]+\|.log.err\|.log.out\|.out.log\|.err.log\)'
# ~~~~~~~~~~~~~~~ QUEUE / QSUB / BSUB LOG VIEWING AND MOVING ~~~~~~~~~~~~~~~
function rmlogs() { # Usage:     catlogs (no arguments)
    #if [[ "$#" == "0" ]] ; then SEARCH_DIRS=. ; else SEARCH_DIRS=$@ ; fi
    NUM_FOUND=$(find . -maxdepth 1  -type f  -regex "${QUEUE_LOGFILE_PATTERN}" | wc -l)
    echo -e "[:OK :] Deleting $NUM_FOUND 'qsub' logs (the files ending with .e1234 or .o456, etc. or .log.err or .log.out)..."
    find . -maxdepth 1 -type f -regex "${QUEUE_LOGFILE_PATTERN}" -delete
    echo -e "[:OK :] Deleted the ${NUM_FOUND} log files.."
}
function catlogs() { # Usage:     catlogs (no arguments)
    if [[ "$#" == "0" ]] ; then SEARCH_DIRS=. ; else SEARCH_DIRS=$@ ; fi
    echo -e "Concatenating all QSUB/BSUB logs in this directory and viewing it in 'less'..."
    find ${SEARCH_DIRS} -maxdepth 1 -type f -regex "${QUEUE_LOGFILE_PATTERN}" -print0 | xargs -0 -I{} paste.pl "FILE={}" {} | s
}
function mvlogs() { # Usage:   mvlogs OUTPUT_DIRECTORY
    # This function moves those annoying qzub logs to the destination directory
    if [[ "$#" != "1" ]] ; then echo -e "[:ERR:] mvlogs needs EXACTLY ONE destination directory!"; return 1; fi
    if [[ ! -d $1 ]]     ; then echo -e "[:ERR:] mvlogs needs an EXISTING DIRECTORY as a destination! The specified directory ($1) appears not to exist."; return 1; fi
    find . -maxdepth 1 -type f -regex "${QUEUE_LOGFILE_PATTERN}" -print0 | xargs -0 -I{} mv {} $1/
    echo -e "[:OK :] Moved all the logs into the directory <$1>"
}
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#function refresh { # Usage:  refresh (no arguments)
#    FAKEFILE=$(mktemp ./tmp.XXXXXX.tmp) ; /bin/rm $FAKEFILE;
#    (>&2 echo -e "Refreshing the filesystem, which is important since the NFS system otherwise takes 60 seconds to update...")
#}

function star_make_index() {
    # This makes an alignment directory for the STAR aligner, when given just a FASTA file and a length.
    # The exact length is not critical, but it should ideally be the same length as the reads, if possible (slightly longer is OK too, but not necessary).
    if [[ "$#" != "2" ]] ; then echo -e "[:ERR:] star_make_index needs an input FASTA file and a 'how long are the reads' parameter!"; return 1; fi
    FAS=$1
    LEN=$2
    CPU_THREADS=8
    if ! [[ ${FAS^^} =~ \.*[.](FASTA|FA)$ ]]; then echo -e "Arg1 must be .fasta or .fa file, but it was: $FAS"; return 1; fi
    if ! [[ ${LEN^^} =~ ^[0-9]+$ ]]; then echo -e "Arg2 must be a (numeric integer) read length, but it was: $LEN"; return 1; fi
    OUT=$(basename $FAS | perl -pe 's/[.](fasta|fa)$//i')
    OUT=$(echo `pwd`/star_output.$OUT)
    (>&2 echo -e "Output file is:  " $OUT)
    (>&2 echo -e "About to generate a STAR genome index. Settings are as follows:")
    (>&2 echo -e "        FASTA: $FAS")
    (>&2 echo -e "       LENGTH: $LEN")
    (>&2 echo -e "   OUTPUT DIR: $OUT")
    (>&2 echo -e "       N CPUS: $CPU_THREADS")
    cmd="mkdir -p $OUT && STAR --runMode genomeGenerate --genomeDir $OUT --genomeFastaFiles $FAS --runThreadN $CPU_THREADS"
    (>&2 echo -e "Here is the command you should now run:\n   $cmd\n   (Copy and paste that command above, or run it with 'qplz' and double quotes: qplz -t $CPU_THREADS -m 8 \"command\""  )
}

function convert_chromosome_to_chr1_for_genome_browser() {
    if [[ "$#" != "2" ]] ; then echo -e "[:ERR:] needs two inputs: 1. a chromosome to turn into 'chr1' and 2. a bam filename to convert"; return 1; fi
    FINDCHR=$1
    IN=$2
    NEWCHR=chr1
    TMPSAM=${IN}--TMP.sam
    if [[ ! -e $IN ]] ; then echo -e "[:ERR:] Your specified input file ($FILE) does not exist!"; return 1; fi

    FINALBAM=${IN/.bam/--${NEWCHR}_only.bam}

    (>&2 echo -e "[CONVERSION UPDATE] Fixing the @SQ lines at the top of the file...")
    samtools view -H $IN | perl -ne "print if (not m/^[@]SQ/ or s/^([@]SQ.*SN:)$FINDCHR(\s)/\$1$NEWCHR\$2/)" >| $TMPSAM
    samtools view    $IN \
	| awk "\$3==\"$FINDCHR\" {print;}" \
	| awk -v OFS='\t' "{\$3=\"$NEWCHR\";print;}" \
	| cat $TMPSAM - \
	| samtools view -b -S - \
	>| $FINALBAM
    /bin/rm $TMPSAM

    (>&2 echo -e "<$FINALBAM> generated! Chromosome changed from '$FINDCHR' to 'chr1'. Original input: <$IN>")
}

function pdf2png() {
    for f in "$@" ; do echo -e "Converting $f..."; convert -verbose -density 72 $f +antialias ${f/.pdf}.png; done
}

function zwcl() {
    zgrep -c '' "$@"
    #for f in "$@" ; do echo -e -n "$f\t"; zgrep -c '' $f; done # don't use zless, it's super slow compared to zcat
}

function pybug() {
    #echo -e "$1"       # First argument
    #echo -e "2 ${@:2}" # Arguments 2 and beyond
    if [[ ! -e "$1" ]]; then
	echo -e "Looks like your (required!) python script <$1> could not be found!"; return 1;
    fi
    echo -e "Running [ipython]..."
    ipython --pdb "$1"     --      "${@:2}"
    #             SCRIPT  DASHES   ARGUMENTS
}

#function docker-begone {
#    echo -e "Stopping and removing ALL DOCKER CONTAINERS. ALL OF THEM!"
#    docker stop $(docker ps -a -q)
#    docker rm $(docker ps -a -q)
#    echo -e "Not even one docker container was spared."
#    echo -e "Clearing out space also..."
#    docker rm $(docker ps -q -f 'status=exited')
#    echo -e "You may also have to, with RUNNING YOUR CONTAINERS, run this: docker system prune -a"
#    echo -e "The file that should be small now is:"
#    ls -lah $HOME/Library/Containers/com.docker.docker/Data/com.docker.driver.*/*.qcow2
#    echo -e "Clearing out space for any 'dangling' docker items (probably there are none)..."
#    docker rmi $(docker images -q -f "dangling=true")
#}

# count bases per line in a fasta file:
# cat x.fa | grep -v '^>' | perl -ne 'chomp; my @a=split(//,$_); my %c=(); for my $x (@a) { $c{lc($x)}++; }; for my $k (keys(%c)) { print($k.qq{=}.$c{$k}."\t"); }; print qq{  <-- \n};'

function hsync() {
    echo -e "[:FYI:] HTML syncing..."
    rsync -avz $HOME/workspace/html_master/ $HOME/web/
}

function fasta2single_line_per_seq() {
    echo -e "[:HEY:] FYI, this script reads from STDIN, and inputs to STDOUT. We'll be waiting for a cat-ed in input FASTA file." >&2 # print to stderr
    if [[ "$#" != 0 ]] ; then echo -e "[:ERR:]] This script takes NO ARGUMENTS. You must 'cat' a FASTA file to pass it in, like this:  cat myfile.fa | fasta2single_line_per_seq | gzip > done.fa.gz  "; return 1; fi
    awk '!/^>/{printf "%s", $0; n="\n"} /^>/{print n $0; n=""} END {printf"%s",n}'
}

function j1() {
    if ! agw_cmd_exists "bsub"; then
	echo -e "[:ERR:] This is NOT a machine on the cluster with the BSUB queue. Connect to the cluster machine first!"; return 1;
    fi
    : "${cpre}=\033}" ## <-- Color prefix, if not already set
    : "${a_end_color:=${cpre}[m}"
    : "${a_ok_color:="$(tput setaf 2)"}"  # Green, if not already set
    : "${a_err_color:="$(tput setaf 1)"}" # Red, if not already set
    : "${a_orange136}:=${cpre}[38;5;136m}"
    : "${a_yellow226}:=${cpre}[38;5;226m}"
    : "${a_blue_bold}:=${cpre}[1;34m}"
    : "${a_red_bold}:=${cpre}[1;31m}"
    ARRAY_JOB_TEXT=$(bjobs -A -u "${USER}" 2>&1) # Captures STDERR+STDOUT
    if [[ "${ARRAY_JOB_TEXT}" =~ .*array\ is\ not\ found.* ]]; then
	echo -e "${a_blue_bold}(No active array jobs.)${a_end_color}"
    else
	echo -e "${a_blue_bold}Array job status (-A):${a_end_color}"
	echo -e "${ARRAY_JOB_TEXT}"
	bjobs -w -A -u "${USER}" # wide to show FULL array names
	echo -e "[:FYI:] To cancel ALL jobs in an array --> bkill -J \"JOBNAME*\" <-- be careful!"
    fi
    echo -e "${a_blue_bold}Current & finished-within-the-last-hour jobs:${a_end_color}"      # memlimit:3 run_time:6 time_left:5 job_group:10 from_host:12 
    JOB_TEXT=$(bjobs -a -o "jobid:8 stat:4 job_name:80 user:4 queue:3 cpu_used:6 max_mem:3 exec_host:18 submit_time:12 finish_time:12 delimiter='|'" 2>&1)
    JOB_TEXT=$(echo -e "${JOB_TEXT}" | perl -pe "s/^(.*[|]RUN.*)\$/${a_ok_color}\$1${a_end_color}/g")
    JOB_TEXT=$(echo -e "${JOB_TEXT}" | perl -pe "s/^(.*[|]DONE.*)\$/${a_orange136}\$1${a_end_color}/g")
    JOB_TEXT=$(echo -e "${JOB_TEXT}" | perl -pe "s/^(.*[|]EXIT.*)\$/${a_err_color}\$1${a_end_color}/g")
    JOB_TEXT=$(echo -e "${JOB_TEXT}" | perl -pe "s/^(.*[|]PEN.*)\$/${a_yellow226}\$1${a_end_color}/g") # pending
    echo -e "${JOB_TEXT}"
    FAILED_JOB_TEXT=$(bjobs -a -x -l  2>&1)    # Capture STDERR and STDOUT both to a variable returns 0 no matter what. If there's no job, it returns the verbatim text "No job found"
    if [[ "${FAILED_JOB_TEXT}" =~ No.*job.* ]]; then
	echo -e "${a_blue_bold}(No recent job failures were found.)${a_end_color}"
    else
	echo -e "[:ERR:]: ${a_red_bold}Jobs that failed (-a -x -l output):${a_end_color}"
	echo -e "${FAILED_JOB_TEXT}"
	echo -e "[:ERR:]: [End of list]"
    fi
}

function jj() {
    j1 | less -S --RAW-CONTROL-CHARS -f --IGNORE-CASE
}

function setsubtract() {
    # input files do NOT need to be sorted
    if [[ "$#" != 2 ]] ; then echo -e "[:ERR:]] You need to pass EXACTLY TWO files to the set subtraction!"; return 1; fi
    if [[ ! -f "$1" ]] ; then echo -e "[:ERR:]] Could not find the specified input file: $1!"; return 1; fi
    if [[ ! -f "$2" ]] ; then echo -e "[:ERR:]] Could not find the specified input file: $2!"; return 1; fi
    grep -F -x -v -f "$2" "$1"
}

function setunion() {
    # input files do NOT need to be sorted
    if [[ "$#" != 2 ]] ; then echo -e "[:ERR:]] You need to pass EXACTLY TWO files to the set union!"; return 1; fi
    if [[ ! -f "$1" ]] ; then echo -e "[:ERR:]] Could not find the specified input file: $1!"; return 1; fi
    if [[ ! -f "$2" ]] ; then echo -e "[:ERR:]] Could not find the specified input file: $2!"; return 1; fi
    cat "$1" "$2" | sort -u
}


#function checkbackup {
#    # checks the MOST RECENT file in /it/backup/log, and gives you the last 10 lines from that file
#    echo -e ""
#    echo -e "Reporting the last 10 lines of the most recent backup on this machine."
#    echo -e "If these lines are not from yesterday or today's date, then something is seriously wrong!"
#    tail -n 10 /it/backup/log/$(ls -1t /it/backup/log/ | head -n 1)
#    TODAY=$(date +"%Y%m%d")
#    YESTERDAY=$(date +"%Y%m%d" --date='1 day ago')
#    LAST_BACKUP_DATE=$(ls -1t /it/backup/log/ | head -n 1 | cut -f 1 -d '-')
#    [[ ("$LAST_BACKUP_DATE" == "$TODAY") || ("$LAST_BACKUP_DATE" == "$YESTERDAY") ]]; RESULT=$?
#    if [[ $RESULT -ne 0 ]] ; then echo -e "***\n**\n*\n******************** WARNING --- last backup date was on $LAST_BACKUP_DATE ************\n*\n**\n***";
#    else echo -e "\nOK: The last backup ($LAST_BACKUP_DATE) was made within the last 2 days.\n"; fi
#}


#function workarchive { # usage: cd /work/projects  then: "workarchive myproj-1234-rna-mouse"  --> will move things to bag_of_holding/work_archive/
#    D=${1%/}
#    DARCH=${D}_ARCHIVE
#    TARGET=/bag_of_holding/work_archive/${D}
#    agw_cmd_exists "ionice" && AGW_IONICE="ionice -c3" || AGW_IONICE="" # ionice doesn't exist on BSD/Mac, so check for it
#    echo -e "We would like to move the directory (without a slash) \"${D}\" to the final TAPE DRIVE target \"${TARGET}\"... sound ok to you? Select a NUMERIC option below:"
#    select yn in "[Cancel]" "Move those files!"; do
#	case $yn in
#	    Move*) sudo mv ./${D} ./${DARCH}
#		 ln -s ${TARGET} ./${D}
#		 eval sudo ${AGW_IONICE} mv ./${DARCH}  ${TARGET}
#		 break;;
#	    *) echo -e "Ok, not doing anything."; break;;
#	esac
#    done
#}

#function truename {
#    qsub -I  -l ncpus=1  -l mem=4gb  -l walltime=24:00:00 -N "INTERACTIVE_for_$USER" -q Interactive -W group_list="interactive"
#}
#
#function qsud {
#    if [[ "$#" == "0" ]] ; then echo -e "[:ERR:] qq (queue submission) needs at least ONE argument script!"; return 1; fi
#    PBS_BIO_GGG="Bio"
#    PBS_BIO_QQQ="bioqueue"
#    PBS_GEN_GGG="General"
#    PBS_GEN_QQQ="genqueue"
#    groupstr=`groups`
#    case "$groupstr" in 
#	*bioqueue*)
#    	    QGRP="$PBS_BIO_GGG"
#	    QQUE="$PBS_BIO_QQQ"
#	    ;;
#	*genqueue*)
#    	    QGRP="$PBS_GEN_GGG"
#	    QQUE="$PBS_GEN_QQQ"
#	    ;;
#	*)
#    	    echo -e "[:ERR:] your username was not in a relevant group -- it must be in either the 'bioqueue' or 'genqueue' groups. This is MANDATORY if qsud is to work!"
#	    return 99
#	    ;;
#    esac
#    cmd=( "qsub" "-q" $QGRP "-V" "-l walltime=320:59:59" "-W group_list=\"$QQUE\"" "$@" ) # 14 days is the longest possible
#    echo -e "About to execute this command. Note that all paths must be FULL PATHS:\n----------\nCOMMAND>      ${cmd[@]}\n----------"
#    "${cmd[@]}" # <- Actually execute. See http://unix.stackexchange.com/questions/131766/why-does-my-shell-script-choke-on-whitespace-or-other-special-characters
#}


function bsubnow() {
    if (( "$#" >= 1 )); then
	PROJNAME=$1;
    else
	PROJNAME='YOUR_PROJNAME_GOES_HERE'
    fi
    if (( "$#" >= 2 )); then
	CMD=$2;
    else
	CMD='YOUR_COMMAND_GOES_HERE'
    fi
    echo bsub -L '/bin/bash' \
	 -R "'span[hosts=1]'" \
	 -q "'medium'" \
	 -R "'rusage[mem=32]'" \
	 -oo "'LOG-%J.bsub.log.out'" \
	 -eo "'LOG-%J.bsub.log.err'" \
	 -n 1 \
	 -J "'${PROJNAME}'" \
	 \"${CMD}\"
}

function bsubtemp() {
    if (( "$#" < 1 )) ; then echo -e "[:ERR:]] Please specify a job name! Note that you probably also want to send this output to STDOUT, so e.g. 'bsubtemp MYJOB > job.sub.sh'"; return 1; fi
    if [[ "$#" == 2 ]] ; then
	MEM=$2
    else
	MEM=4  # gigabytes
    fi
    if ! agw_is_numeric "${MEM}"; then
	echo "[:ERR:] Your second argument, if included, MUST be an integer (the amount of RAM to request, in GB)! Your argument was this: ${mem}" >&2;
	return 1;
    fi
    JJJ=${1/ /_} # spaces --> '_'
    echo -e "#!/bin/bash"
    echo -e "set -euo pipefail; shopt -s nullglob; shopt -s globstar;"
    echo -e "#BSUB -L /bin/bash                # Ensure that we are using BASH"
    echo -e "#BSUB -R 'span[hosts=1]'          # No splitting across hosts"
    echo -e "#BSUB -q medium                   # short=2 hours, medium=24 hours"
    echo -e "#BSUB -R 'rusage[mem=${MEM}]'     # In GB"
    echo -e "#BSUB -n 1                        # N threads"
    echo -e "#BSUB -J ${JJJ}"
    echo -e "#BSUB -o ${JJJ}-%J-%I.bsub.log.out   # or '-oo' to OVERWRITE (instead of appending)"
    echo -e "#BSUB -e ${JJJ}-%J-%I.bsub.log.err   # or '-eo' to OVERWRITE (instead of appending)"
    echo -e ''
    echo -e ": \"\${LSB_JOBID:=}\" # a non-defined ID would become blank"
    echo -e "if [[ -z \"\${LSB_JOBID}\" ]]; then"
    echo -e "    echo \"[:ERR:] ERROR: You should NOT run this as a shell script! Correct way -->   bsub < scriptname.sh      <-- note: the '<' is important! Do not omit it.\"; "
    echo -e "    exit 1; "
    echo -e "fi"
    echo ''
    # 'bhist' has more info too: # bhist -w -l -a -n 99 769084 | less -S
}

function agw_is_numeric() {
    numeric_regex='^[0-9]+$'
    if [[ "$1" =~ ${numeric_regex} ]]; then
	return 0 # IS a number (0 is 'good' in bash)
    else
	return 1 # NOT a number
    fi
}


# Logs you into a fast interactive node
alias qrush='bsub -q long   -n 4   -R '\''span[hosts=1] rusage[mem=4]'\'' -Is bash' # was previously 'qrsh' 

function bbq() { # bsub, be quick!
    # Usage:   bbq "my command here"
    # Note:    * Outputs log files to THE CURRENT DIRECTORY!
    #          * Makes a temp file using 'mktemp'
    #          * Blocks until the submitted job is complete (with bsub -K).
    #          * It is NOT OK to cancel out of the submitted job! It will cancel the job!
    : "${cpre}=\033}" ## <-- Color prefix, if not already set
    : "${a_end_color}:=${cpre}[m}"
    : "${a_blue_bold}:=${cpre}[1;34m}"
    : "${a_green}:=${cpre}[32m}"
    echo -e "${a_blue_bold}BSS${a_end_color}: ${a_blue_bold}B${a_end_color}sub ${a_blue_bold}B${a_end_color}e ${a_blue_bold}Q${a_end_color}uick!"
    if [[ "$#" < 1 || "$#" > 2 ]] ; then echo -e "\n[:ERR:] BBQ: You must specify EXACTLY ONE command to add to the queue run---put your command in quotes! Example:  bbq \"ls -al\"  "; return;  fi
    cmd=$1
    
    if (( "$#" >= 2 )); then
	mem=$2
	if ! agw_is_numeric "${mem}"; then
	    echo "[:ERR:] Your second argument, if included, MUST be an integer (the amount of RAM to request, in GB)! Your argument was this: ${mem}" >&2;
	    return 1;
	fi
    else
	mem=4 # GB
    fi
    ttt=$(mktemp --suffix=".${USER}.bsub.sh")
    jobname="Q_${USER}_$(date +%s)"
    echo       -e "(Remember that backslashes in your command may need to be doubled.)"
    echo       -e "(Remember that DOLLAR SIGNS MUST BE ESCAPED! So use \\$ instead of '$'.)"
    echo       -e "Submitting this (temporary) script: ${a_blue_bold}${ttt}${a_end_color}"
    echo       -e "Command to run:"
    printf "%s\n" "${cmd}"
    echo       -e ""
    bsubtemp "${jobname}" ${mem}    >| ${ttt}
    printf "%s\n" ""                >> ${ttt}
    printf "%s\n" "${cmd}"          >> ${ttt}
    printf "%s\n" ""                >> ${ttt}
    #bsub -K   -q 'short' < ${ttt}
    echo -e "Running the job here locally... blocking until it finishes!"
    echo -e "(You probably want to be running this job in SCREEN or TMUX.)"
    echo -e "You can check the BSUB command with -->  ${a_blue_bold}less -S ${ttt}${a_end_color}"
    echo -e "${a_green}[WAITING FOR JOB \"${jobname}\"... DO NOT CTRL-C THIS JOB!]${a_end_color}"
    echo -e "${a_green}[WARNING: IF YOU CTRL-C, THE QUEUE JOB IS ABORTED, EVEN IF IT IS RUNNING!]${a_end_color}"
    echo -e "${a_green}View the output LIVE with: tail -f PROJECT_ID_HERE.bsub.log.err <-- only works for ONE file at a time${a_end_color}"
    bsub -K < ${ttt}
    echo -e "${a_green}[DONE]${a_end_color}"
}

function delete_android_file_transfer_on_mac() {
    PID=$(ps -fe | grep "[A]ndroid File Transfer Agent" | awk '{print $2}')
    if [[ -n ${PID} ]]; then kill ${PID}; fi;
    mv "/Applications/Android File Transfer.app/Contents/Resources/Android File Transfer Agent.app" \
       "/Applications/Android File Transfer.app/Contents/Resources/Android File Transfer Agent DISABLED.app"
    mv "${HOME}/Library/Application Support/Google/Android File Transfer/Android File Transfer Agent.app" \
       "${HOME}/Library/Application Support/Google/Android File Transfer/Android File Transfer Agent DISABLED.app"
    osascript -e 'tell application "System Events" to delete every login item whose name is "Android File Transfer Agent"'
    echo "Done disabling it. Note that the files have been RENAMED, and not totally deleted!"
}

function posterr() {
    # diagnose postgres issues
    echo "select * from stl_load_errors order by starttime desc;"
}

function gitstory() {
    if [[ "$#" != 1 ]] ; then
	echo -e "[:ERR:] You must specify EXACTLY ONE filename."; return;
    fi
    F=$1
    if [[ ! -f $F ]]; then
	echo -e "[:ERR:] Apparently your specified file was not found??? Check this file: $F"; return;
    fi

    echo "[:OK:] Checking the last few checked-into-git versions of <$F>..."
    filebase=$(basename -- "$F")
    extension="${filebase##*.}"
    filepre="${filebase%.*}"
    git show HEAD~1:$F > $filebase.01.git.old_from_git_1_rev_back.01.${extension}
    git show HEAD~2:$F > $filebase.02.git.older_2_revisions__back.02.${extension}
    git show HEAD~4:$F > $filebase.04.git.older_4_revisions__back.04.${extension}
    git show HEAD~8:$F > $filebase.08.git.older_8_revisions__back.08.${extension}
    echo "[:OK:] Generated a bunch of '.git.old' files"
    echo "[:FYI:] If you're looking for something really specific, remember you can use:  git log -p FILENAME | less -S"
}

PG_DB="/usr/local/var/postgres"
alias pg_start="pg_ctl -D ${PG_DB} start"
alias pg_stop="pg_ctl  -D ${PG_DB} stop"


alias cheat="echo \
\">> Rscript/R read STDIN: One-liner R and perl extravaganza for plotting contig lengths:  cat contigs.fasta  | perl -ne 'next if not m/^>/; chomp; m/>NODE_(\d+).*length_([\d.]+).*cov_([\d.]+)/; print join(qq{\t}, \\\$1, \\\$2, \\\$3).qq{\n};' | Rscript --vanilla -e 'ddd=read.table(file(\\\"stdin\\\"),header=F,row.names=1); pdf(\\\"a.pdf\\\"); plot(ddd[,1], ddd[,2]); dev.off();' \" ${NL}\
\">> UNICODE get character as shell escape: printf YOURCHAR | hexdump , then convert that like this: printf \\\"\\\\xE2\\\\x98\\\\xA0\\\" \" ${NL}\
\">> Amazon AWS / S3: upgrade awscli on an instance:  pip install awscli --upgrade --user   \" ${NL}\
\">> DOCKER: list even EXITED containers: docker ps -a \" ${NL}\
\">> DOCKER: connect interactively no matter what: docker run --name prokka -v '/:/MacRoot/' -i -t --entrypoint '/bin/bash' YOURIMAGE \" ${NL}\
\">> DOCKER: start a container from an image 1: docker run --name NEWNAME --rm -i -t IMGNAME bash \" ${NL}\
\">> DOCKER: start a container from an image 2: docker run -it 0134abd1356  <-- check 'docker images' for a list of images \" ${NL}\
\">> DOCKER: attach to container: docker exec -it CONTAINERNAME bash \" ${NL}\
\">> EMOJI TO TERMINAL: example: a snake is echo $'\xF0\x9F\x90\x8D' (See http://apps.timwhitlock.info/emoji/tables/unicode) \" ${NL}\
\">> SAFARI: Disable page previews: defaults write com.apple.Safari DebugSnapshotsUpdatePolicy -int 2 \" ${NL}\
\">> Unzip files into SUBDIRECTORIES always: ls *.zip|awk -F'.zip' '{print \\\"unzip \\\"\\\$0\\\" -d \\\"\\\$1}'|sh  \" ${NL}\
\">> ZIP on Mac without the dot files: zip -r -X out.zip input_directory_here    -x \\\"*.DS_Store\\\" \" ${NL}\
\">> RAM/Filesystem: clear out disk cache, recover RAM: purge \" ${NL}\
\">> MAC: what program is using a disk / preventing eject: sudo lsof -xf +d /Volumes/THEVOL \" ${NL}\
\">> MAC: lock a file, for example to prevent Dropbox from replacing a custom icon: chflags uchg ~/Dropbox/Icon\\\$'\\r'  (use nouchg to unlock a file)\" ${NL}\
\">> Mac disk: specific file I/O: fs_usage <programname> \" ${NL}\
\">> Mac disk: filesystem I/O:    fs_usage -w | grep -v '0\\.0'  \" ${NL}\
\">> Mac set startup disk: sudo bless -mount /Volumes/YOURDISK -setBoot \" ${NL}\
\">> MAC: show weird file flags: ls -l -@ \" ${NL}\
\">> MAC: rebuild spotlight for the boot drive only: sudo mdutil -E / \" ${NL}\
\">> Mac Time Machine: exclude/check: tmutil isexcluded/tmutil addexclusion (-p) PATH \" ${NL}\
\">> Mac Time Machine: delete backups: tmutil delete /Volumes/DISK/Backups.backupdb/COMPNAME/ \" ${NL}\
\">> MAC: recursively clear worthless quarantine flags: xattr -r -d com.apple.quarantine FILENAME \" ${NL}\
\">> MAC: delete impossible-to-delete files find FILE -flags schg -exec chflags noschg {} \\; \" ${NL}\
\">> MAC: show library: chflags nohidden ~/Library/ \" ${NL}\
\">> MAC: batch change modification time: find . -print0 | xargs -0 SetFile -d '12/31/2012 12:00:00 PM' \" ${NL}\
\">> FIND: delete files when argument list too long: find . -iname '*whatever*' -delete \" ${NL}\
\">> MAC: No quarantine warn  : defaults write com.apple.LaunchServices LSQuarantine -bool NO \" ${NL}\
\">> MAC: check code signing: codesign -vvv /Applications/iTunes.app \" ${NL}\
\">> MAC: No .DS_Store servers: defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool YES \" ${NL}\
\">> MAC: Select in QuickLook (buggy!): defaults write com.apple.finder QLEnableTextSelection -bool YES \" ${NL}\
\">> MAC: No smooth scroll: defaults write -g NSScrollAnimationEnabled -bool NO \" ${NL}\
\">> Mac/cron : edit crontab cron.tab with emacs: env EDITOR=emacs crontab -e \" ${NL}\
\">> Delayed sudo: sudo sh -c \\\"(sleep 3600; do your command here )\\\" \" ${NL}\
\">> Display image in ASCII on the command line: 'tiv' IMAGENAME \" ${NL}\
\">> Image SIPS: PNG -> JPEG: mkdir outjpegs; sips -s format jpeg *.png --out outjpegs \" ${NL}\
\">> Imagemagick SVG -> PNG: convert -format png -background transparent -density 300 in.svg out.png (see also the -resize 100 option)\" ${NL}\
\">> Imagemagick convert multi-page pdf: for a in \\\$(seq 90); do echo \\\"Converting page \\\$a...\\\"; convert -quality 80 your.pdf[\\\$a] OUT_page_\\\$a.jpg ; done   (note: REQUIRES ghostscript (brew install gs) or it will crash) \" ${NL}\
\">> Imagemagick convert recursive: find ./ -name \\\"*.jp*\\\" -print0 | xargs -0 -I{} convert -resize 1024x768 -quality 85 {} {}  # or resize 50%\" ${NL}\
\">> Imagemagick convert all PDFs in a dir: for f in *.pdf ; do echo \\\"Converting \\\$f...\\\"; convert -verbose -density 144 \\\$f +antialias \\\${f/.pdf}.png; done \" ${NL}\
\">> Imagemagick convert PDF -> PNG w/antialias and downsample: convert -verbose -density 144 in.pdf +antialias out.png   (note: REQUIRES ghostscript (brew install gs) or it will crash)  Note that argument order is very important and may not be correct here. It is also very slow..\" ${NL}\
\">> MP3: Convert m4a/ogg->mp3 for name in *.ogg; do ffmpeg -i \\\"\\\$name\\\" -ab 256k -map_metadata 0:s:0 \\\"Converted_\\\${name/.ogg/.mp3}\\\"; done; \" ${NL}\
\" \" ${NL}\
\">> RSYNC to amazon instance with an ssh key: rsync -avz -e \\\"ssh -i ~/pems/your_pem.pem\\\" LOCALFILE ec2-user@REMOTEINSTANCE.COM:  <-- DO NOT FORGET THE ':'!!! \" ${NL}\
\">> Check directories for differences (by modification time): ionice -c3 rsync --dry-run --delete -vr /dirA /dirB \" ${NL}\
\">> Find all .R files in a directory:   find ./ -name \\\"*.R\\\" -exec ls \'{}\' \\\; \" ${NL}\
\">> DIFF directories:   diff -rq DIR1 DIR2 \" ${NL}\
\">> DIFF with side-by-side and line numbers: sdiff -l file1.txt file2.txt | cat -n | grep -v -e '(${DLR}'  \" ${NL}\
\" \" ${NL}\
\" \" ${NL}\
\">> PYTHON: iPython auto-reload a module before each run: %load_ext autoreload (newline)  %autoreload 2  from foo import some_function (<-- the import is only needed ONE time now!) \" ${NL}\
\">> PYTHON logging: RED error messages, but only if we are in the 'DEBUG' (detailed output) mode:  logging.error('My message')      and then:                       if logging.getLogger().isEnabledFor(logging.DEBUG):   logging.error(f'MORE {e}') \" ${NL}\
\">> PYTHON debug a crashing program (worse):  python -m pdb YOURPROG -some -args -here . 'c' continues execution, 's' steps. \" ${NL}\
\">> PYTHON debug a crashing program (better): ipython --pdb YOURPROG --  -more -args -here  'c' continues execution, 's' steps. \" ${NL}\
\">> PYTHON debug a crashing program by enterint the debugger at a specific point:  import pdb; pdb.set_trace() \" ${NL}\
\">> PYTHON / PIP install locally to home directory -> .local: pip2.7 install --user PACKAGENAME \" ${NL}\
\">> PYTHON / PIP install locally to home directory -> .local: pip2.7 install --ignore-installed --install-option=\\\"--prefix=$BINFPYROOT\\\" PACKAGENAME \" ${NL}\
\">> PYTHON debug a crashing program: Put this in the code to enter the python debugger on a line:  import pdb; pdb.set_trace() \" ${NL}\
\" \" ${NL}\
\">> BIOM format: convert FROM BIOM   : biom convert -i INPUT.biom -o TABDELIM.txt  --to-tsv  --header-key=taxonomy \" ${NL}\
\">> BIOM format: convert BACK TO BIOM: biom convert -i TABIN.txt  -o OTUTABLE.biom --to-hdf5 --table-type=\\\"OTU table\\\" --process-obs-metadata taxonomy \" ${NL}\
\">> R: Unload all packages: lapply(paste('package:',names(sessionInfo()$otherPkgs),sep=""),detach,character.only=T,unload=T) \" ${NL}\
\">> R: set vector or list names by VARIABLE instead of plain text: Since you cannot do x='first'; y='second'; c(x='a', y='b'), you must instead do this: setNames(c('a','b'), c(x, y))  (which will set the names accordingly, in a single command.\" ${NL}\
\">> R: RMD/KNITR render RMD headless: script -e 'rmarkdown::render(\\\"/path/to/the.Rmd\\\", \\\"html_document\\\")'  (or you can specify output_file='path_to_output_file.html')   \" ${NL}\
\">> R: RMD/KNITR: write markdown VERBATIM in R \\\`\\\`\\\`{r results='asis'} (newline) cat('\n\n## HERE is a programmatically-defined SECTION in Rmd\n')  \" ${NL}\
\">> R: A 'stop' and 'stopifnot' that actually work in RStudio:  stop_infloop   <- function(msg) { stop(msg); while(TRUE) {} }           and         waitifnot <- function(cond) { if (!cond) { stop_infloop(paste(deparse(substitute(cond)), ' is not TRUE.')) } }    \" ${NL}\
\">> R: List (same # elements per item) --> Data frame (list to data.frame / list to table): do.call(rbind.data.frame, YOUR_LIST_HERE)   \" ${NL}\
\">> R: Save copy of figure as pdf: dev.copy2pdf() \" ${NL}\
\">> R: Convert columns of a dataframe to factors (from char): fact.df   <- char.df; fact.df[] <- lapply(char.df[], as.factor) \" ${NL}\
\">> R: Prevent blank page in PDF: pdf(..., onefile=FALSE) \" ${NL}\
\">> R: Aggregate rows / average rows with same name (mean): mAGG <- t(sapply(by(MAT,rownames(MAT),colMeans),identity)) \" ${NL}\
\">> R: Read bzip/gz file:  x <- read.table(gzfile(\\\"name.bz2\\\") (gzfile supposedly handles .txt/.xz/.bz2/.gz) \" ${NL}\
\">> R: Read bzip/gz file line by line:  conn=gzcon(file('in.txt.gz','r')); while(TRUE) { lines22.vec=readLines(conn,n=22); if (0==length(lines22.vec)){break; } } close(conn); \" ${NL}\
\">> R: Read from stdin:    x <- read.table(pipe(\\\"cat something name.bz2 | bunzip2\\\") \" ${NL}\
\">> R: traceback() - to properly debug. Also: options(error=recover()) \" ${NL}\
\">> R: t.test failing? Use tryCatch: tryCatch(something, error=function() { return('NA'); }); \" ${NL}\
\">> R: Need to un-list things? Use unlist! \" ${NL}\
\">> R: PLOT: Perpendicular axis labels: par(las=2) (1 = horiz, 3 = vertical) \" ${NL}\
\">> R: PLOT: draw beyond the axes / off / outside the graph region: par(xpd=T/F/NA) \" ${NL}\
\">> R: PLOT: square plot: par(pty='s') \" ${NL}\
\">> R: PLOT: heatmap colors: color_function = grDevices::colorRampPalette(c('cyan', 'blue', 'black', 'red', 'yellow')); color_function(n=10) \" ${NL}\
\">> R: PLOT: heatmap colors: COOL: black->blue->cyan->yellow:  grDevices::colorRampPalette(c('black', 'blue', '#0099FF', 'yellow'))(n=10)                        <-- note the 10 here \" ${NL}\
\">> R: PLOT: heatmap colors: COOL, longer ramp:                grDevices::colorRampPalette(c('black', '#000066', 'blue', '#0099FF', '#BBCC00', 'yellow'))(n=10)  <-- note the 10 here \" ${NL}\
\">> R: PLOT: heatmap colors: WARM: black->red->orange->yellow: grDevices::colorRampPalette(c('black', 'red', 'yellow'))(n=10)                                    <-- note the 10 here \" ${NL}\
\">> R: PLOT: pheatmap symmetrical around zero: library(pheatmap); symcol = colorRampPalette(c('orange','black','cyan'))(n=5); bounds = 3; pheatmap(DATA, color=symcol, breaks=seq(from=-bounds, to=bounds, length.out=length(symcol)+1), border=NA, cluster_rows=T, cluster_cols=T, fontsize_row=5);   \" ${NL}\
\">> R: PLOT / PHEATMAP: nice heatmap part 1: library(pheatmap); pheatmap(DATA,  color=grDevices::colorRampPalette(c('black', 'red', 'yellow'))(n=10),   border=NA,  cluster_rows=T,  cluster_cols=F,  main='Heatmap',  fontsize_col=9,  fontsize_row=9,  display_numbers=T,  fontsize_number=4);   \" ${NL}\
\">> R: PLOT / PHEATMAP: nice heatmap part 2: library(pheatmap); library(viridis); pheatmap(DATA, color=viridis::magma(20), border=NA, cluster_rows=T, cluster_cols=F, main='Heatmap', fontsize_col=9, fontsize_row=9, display_numbers=F, fontsize_number=4);   \" ${NL}\
\">> R: PLOT: pheatmap clustering PART of the heatmap only:   cluster_and_return_ids = function(dd, distmethod='euclidean', linkage='complete') {    if (nrow(dd) == 1) { return(rownames(dd)) } else if (is.null(dd) || nrow(dd) == 0) { return(c()) }  dists=dist(dd, method=distmethod);  clusts = hclust(dists, method=linkage);  return(clusts$labels[clusts$order]) };  lab.1 = cluster_and_return_ids(l2n.mat[probe.annot.df$Comment == 'TYPE1', , drop=F]);    lab.2 = rownames(l2n.mat)[probe.annot.df$Comment != 'TYPE1'];   reordering_labels.vec = c(lab.1, lab.2);   l2n.mat = l2n.mat[reordering_labels.vec, ]            \" ${NL}\
\">> R: PLOT: pheatmap with ROW labels (the trick is that the *rownames* must match, which is not true for column annotation!): library(pheatmap); m=matrix(rnorm(100),ncol=5); rownames(m) <- paste('R',1:nrow(m)); rannot=data.frame('RANNOT1'=c(rep('A',10), rep('B',7), rep('C',3)), row.names=rownames(m)); pheatmap(m, annotation_row=rannot, annotation_colors=list('RANNOT1'=c('A'='red','B'='blue','C'='green'))); NOTE: pheatmap annotation frequently does NOT like NAs or non-character columns, and will crash with baffling messages. Try this to character-ize your row annotation: Example:  annot.sanitized[ , ] = lapply(rannot[, ], as.character); annot.sanitized[is.na(annot.sanitized)] = 'NONE' # text, not an NA value \" ${NL}\
\" \" ${NL}\
\">> R: GGPLOT2: side-by-side barplot without removing 'zero-item' categories (i.e. a blank spot for a missing category): ggplot(DATA, aes(x=CATEGORY, fill=US_STATE)) + geom_bar(position=position_dodge(preserve=\\\"single\\\")) + \" ${NL}\
\">> R: GGPLOT2: geom_boxplot: ggplot(dat, aes(x=gene_name, y=EXPRESSION)) + geom_boxplot(aes(fill=repClass), outlier.alpha=0.5, outlier.size=0.5) + \" ${NL}\
\">> R: GGPLOT2: add line of best fit:   geom_smooth(method='lm', col='red') + ... (by default, uses the same x and y as in the ggplot setup)  \" ${NL}\
\">> R: GGPLOT2: omit the legend for only CERTAIN parameters / aesthetics:   + guides(color=FALSE) or + guides(fill=FALSE)  . Useful if there are just way too many categories.\" ${NL}\
\">> R: GGPLOT2: custom FILL colors (or outline color with just 'scale_color_manual'): scale_fill_manual(values=c('#999999', '#E69F00', '#56B4E9')) \" ${NL}\
\">> R: GGPLOT2: rotate axis labels (x-axis perpendicular): YOURGGPLOT + theme(axis.text.x = element_text(angle=90, vjust=1, size=12, hjust=1))  \" ${NL}\
\">> R: GGPLOT2: multi plots (facets): YOURPLOT + facet_grid(. ~ DRUG_TREATMENT, scales='free_x', space='free_x') <-- replace the '.' for a 2-way facet. The format is: x ~ y, with a '.' for an unused facet dimension. \" ${NL}\
\">> R: GGPLOT2/DPLYR: pairwise correlations of everything BY GROUP in a melted matrix:  melted.tib %>% group_by(SCHOOL_TYPE, US_STATE) %>% do(data.frame(Cor=t(cor(.[['TEST_SCORE']], .[['STUDENT_AGE']] , method='spearman' ) )))    \" ${NL}\
\">> R: correlation plot (does not work with ggsave, though, you have to use pdf() or png()): pairwise correlations of a matrix, visualized: library('corrplot'); cors = cor(data.df, method='spearman'); corrplot(cors, method='square', order='hclust', hclust.method='complete', addgrid.col='#00000000', rect.lwd=1, tl.cex=0.5, tl.col=c('red','blue'), tl.srt=90);    \" ${NL}\
\">> R: GGPLOT2/DPLYR/RESHAPE: melt an input matrix with MULTIPLE ANNOTATION COLMNS (not just one!): your_tibble %>% reshape2::melt(id.vars=c('GeneName','ProteinType','CodeClass','OtherID'), variable='SAMPLE_COLUMN', value.name='EXPRESSION_NEW_OUTPUT_COLUMN') \" ${NL}\
\">> R: GGPLOT2: melted sample data: m1=matrix(runif(80),nrow=10, dimnames=list(paste('Gene',1:10), LETTERS[1:8])); library(dplyr); library(reshape2); melted = reshape2::melt(m1, value.name='EXPRRESSION') %>% \\\`colnames<-\\\`(c('GENE','SAMP','EXPR')) \" ${NL}\
\">> R: DPLYR: how to CAST (dcast) a melted dataset back into a matrix-like structure: x.melt = YOUR_LONG_DATA_STRUCTURE; reshape2::dcast(x.melt, US_STATE ~ YEAR, value.var='annual_income')) \" ${NL}\
\">> R: GGPLOT2: equivalent of par(pty='s') (square plots with X / Y axes the same size): YOURPLOT + coord_fixed() \" ${NL}\
\">> R: GGPLOT2: scatterplot: ggplot(melted.df, aes(x=CATEGORY)) + geom_bar(aes(weight=VALUE, fill=CATEGORY)) \" ${NL}\
\">> R: GGPLOT2: barplot basic example: ggplot(melted.df, aes(x=CATEGORY)) + geom_bar(aes(weight=VALUE, fill=CATEGORY)) \" ${NL}\
\">> R: GGPLOT2: barplot reordered by GROUP2, but still plotted by individual 'SOMETHING1': ggplot(melt.df, aes(x=reorder(SOMETHING1, as.integer(as.factor(GROUP2))))) + geom_bar(aes(weight=VALUE, fill=GROUP2)) \" ${NL}\
\">> R: GGPLOT2: barplot reordered AND 'faceted' by another group: ggplot(melt.df, aes(x=reorder(MAINCATEGORY, 0.5*OTHERGROUP+0.1*THING) )) + geom_bar(aes(weight=VALUE, fill=OTHERGROUP)) + theme_minimal() + theme(axis.text.x = element_text(angle=90, vjust=1, size=12, hjust=1)) + facet_grid(. ~ OTHERGROUP, scales='free_x', space='free_x') \" ${NL}\
\">> R: GGPLOT2: barplot reordering example: reorder_by_size <- function(x) { factor(x, levels=names(sort(table(x)))) }; ggplot(mpg, aes(reorder_by_size(class))) + geom_bar() \" ${NL}\
\">> R: GGPLOT2: heatmap-ish (not as good as pheatmap, and does NOT cluster): ggplot(data %>% mutate(VALUECOL=log2(VALUECOL)), aes(x=SAMPLENAME, y=GENENAME)) +  geom_tile(aes(fill=VALUECOL)) +  scale_fill_gradientn(colors=c('red','white','blue'), name='Description goes here') +  theme_minimal() +   theme(axis.text.x = element_text(angle=90, vjust=1, size=12, hjust=1)) \" ${NL}\
\">> R: GGPLOT2: histogram: ggplot(data %>% mutate(VALLOG=log2(VALLINEAR)), aes(VALLOG)) + geom_histogram(bins=30, col='#0000FF33', fill='#FF000088') + labs(title='Hist', x='Val', y='Count') + theme_minimal()  # or breaks=seq(10,20,by=5) if you want to manually specify the bin breaks \" ${NL}\
\">> R: GGPLOT2: histogram ALTERNATE method of log scaling: ggplot(data %>% mutate(VALLOG=log2(VALLINEAR), aes(VALLOG)) + geom_histogram(bins=30, col='#0000FF33', fill='#FF000088') + scale_x_log10() + scale_y_log10() + labs(title='Hist', x='Val', y='Count') + theme_minimal() \" ${NL}\
\" \" ${NL}\
\">> R: PLOT: totally blank plot: plot(c(0,1),c(0,1),ann=F,bty='n',type='n',xaxt='n',yaxt='n') \" ${NL}\
\">> R: multiply/divide/'sweep' a matrix by a vector, line by line / row by row: sweep(yourmatrix, 2, yourvec, '/'); stopifnot(ncol(yourmatrix)==length(yourvec)); <-- replace '/' with '*' to multiply \" ${NL}\
\">> R: find attributes of a variable: attr(x, 'theAttribute'); Works when names()/attributes() fails! \" ${NL}\
\">> R: inspect object: str(...) \" ${NL}\
\">> R: cut a data structure (e.g. a vector) into bins, like a histogram: cut(...) \" ${NL}\
\">> R: factor -> Integers: unclass(...) \" ${NL}\
\">> R: Collapse a list down to a basic vector: unlist(...) \" ${NL}\
\">> R: Remove names from a structure: unname(...) \" ${NL}\
\">> R: Resize terminal width / columns: options(width=Sys.getenv(\\\"COLUMNS\\\")) \" ${NL}\
\">> R: write.table(DATA, file='x.txt', row.names=T, col.names=NA, sep='\t', quote=F)  \" ${NL}\
\">> R: make libraries usable by non-root users: sudo chmod -R a+r /usr/local/lib/R ; sudo find /usr/local/lib/R -type d | sudo xargs chmod a+x \" ${NL}\
\">> R: run in the queue: qplz \\\"R CMD BATCH script.R\\\" or RScript, but be sure to 'library(methods)' if you use horrendous Rscript \" ${NL}\
\">> R: Mac: read from clipboard: y=data.matrix(read.delim(pipe(\\\"pbpaste\\\"))); \" ${NL}\
\">> R: PACKAGES: Pick CRAN mirror, no GUI popup (install.packages): chooseCRANmirror(graphics=F) \" ${NL}\
\">> R: PACKAGES: Install package from source:  R CMD INSTALL packagename.tar.gz  (or use biocLite(...) or install.packages(...)) \" ${NL}\
\">> R: PACKAGES: sessionInfo(): show packages and versions of installed packages. ls('package:something') shows a summary of package contents, and help(library='packagename') will show package contents in more detail. '.libPaths()' shows lib dirs. \" ${NL}\
\">> R: PACKAGES: update all installed packages: update.packages(ask=FALSE, checkBuilt=TRUE) \" ${NL}\
\">> R: PACKAGES: install package from BIOCONDUCTOR without root: source('http://www.bioconductor.org/biocLite.R'); biocLite(lib=head(unlist(strsplit(Sys.getenv('R_LIBS'),':')),1), lib.loc=head(unlist(strsplit(Sys.getenv('R_LIBS'),':')),1), pkgs=c('PACKAGENAMEHERE')) \" ${NL}\
\">> R: PACKAGES: install package from CRAN without root: install.packages(repos='http://cran.cnr.berkeley.edu/', dependencies=TRUE, lib=head(unlist(strsplit(Sys.getenv('R_LIBS'),':')),1), pkgs=c('PACKAGENAMEHERE')) \" ${NL}\
\">> R: BED->GRanges: BED file to GeneRanges / GenomicRanges / GRanges object: use 'rtracklayer': library(rtracklayer); gr = rtracklayer::import(rmsk_bed, format='bed'); stopifnot('GRanges' %in% (class(gr))[1]); stopifnot(all(start(gr)<=end(gr))) \" ${NL}\
\" \" ${NL}\
\" \" ${NL}\
\">> R/DPLYR/TIBBLE/DATAFRAME: replace NA with a value:   STRUCTURE %>% base::replace(., is.na(.), 0.00) \" ${NL}\
\">> R/DPLYR/TIBBLE: round a column:   TIB %>% mutate(NEWCOL=signif(OLDCOL,2) \" ${NL}\
\">> R/DPLYR/TIBBLE: get the top element per category. Here, top income per US county on a per-state basis:   TIB %>% group_by(US_STATE) %>% arrange(desc(INCOME_PER_COUNTY)) %>% filter(row_number()==1)  . For top and bottom, you could say filter(row_number()==1 | row_number()==n())  . However, note that that will always return only ONE row, whereas we might want two in the case where a state had only one county, in which case we would want: ... %>% dplyr::slice(c(1,n()))  <-- this will double-return the same row for both 'top' and 'bottom' if there is only one row. Do not omit the 'dplyr::' or else you will get the wrong SLICE function! \" ${NL}\
\">> R/DPLYR/TIBBLE: RENAME a column to a variable: tib %>% dplyr::rename(!!variable_goes_here := 'Literal_Column_Name_To_Replace'); <-- note that 'rename' and 'select' both can be overridden by other packages, and also have a dplyr variant with TOTALLY DIFFERENT BEHAVIOR     \" ${NL}\
\">> R/DPLYR/TIBBLE: READR read QUIETLY / not verbose: readr::read_tsv(..., progress=F, col_types=cols()); <-- super non-intuitive way to suppress printing     \" ${NL}\
\">> R/DPLYR/TIBBLE: split tab-delim fields into a TABLE / matrix: tempsplits = sapply(YOUR_CHAR_DATA_OF_INTEREST, strsplit, '\t'); final.tib = as_tibble(do.call(rbind, lapply(tempsplits, rbind)));   OR even better, you can use 'stringr' and: as.data.frame(t(do.call(cbind, stringr::str_split(YOUR_CHAR_VECTOR, pattern='\t')))); \" ${NL}\
\">> R/DPLYR/TIBBLE: Mutate only CERTAIN columns: my.tib %>% mutate_at(vars(matches('(snakes|cakes)')), funs(log2(1 + .) )) \" ${NL}\
\">> R/DPLYR/TIBBLE: Aggregate a small number of rows in a tibble: mytib %>% group_by(MYGRPCOL) %>% summarize(x=mean(OTHERVALUE), n=n()) %>% ungroup() \" ${NL}\
\">> R/DPLYR/TIBBLE: Aggregate multiple rows BY A PASSED-IN-VARIABLE in a tibble (way 1 of 3): mytib %>% group_by(MYGRPCOL) %>% summarize_at(.vars=c('colA','colB','colC'), .funs=c('NEWSUM'='sum', 'NEW_MEDIAN'='median')) %>% ungroup() \" ${NL}\
\">> R/DPLYR/TIBBLE: Aggregate multiple rows BY A PASSED-IN-VARIABLE in a tibble (way 2 of 3): mytib %>% group_by(MYGRPCOL) %>% summarize_at(vars(matches('^COUNT_')), funs('FINALSUM'=sum, 'FINALMEAN'=mean)) %>% ungroup() \" ${NL}\
\">> R/DPLYR/TIBBLE: Aggregate multiple rows BY A PASSED-IN-VARIABLE in a tibble (way 3 of 3, probably the best) if you also want the N elements in each group (n()): mytib %>% group_by(MYGRPCOL) %>% mutate(NCOUNT=n()) %>% group_by(MYGRPCOL, NCOUNT) %>% summarize_at(vars(matches('^COUNT_')), funs('FINALSUM'=sum, 'FINALMEAN'=mean)) %>% ungroup() \" ${NL}\
\">> R/DPLYR/TIBBLE: tibble to data frame with rownames:    df  = tibble::column_to_rownames(as.data.frame(tib), var='COLUMN_NAME_THAT_BECOMES_ROWNAME')  \" ${NL}\
\">> R/DPLYR/TIBBLE: data frame (with rownames) to tibble:  tib = tibble::rownames_to_column(df, 'New_Column_Name_From_Rowname') \" ${NL}\
\">> R/DPLYR/TIBBLE: set rownames in dplyr in a data frame:  tib %>% \\\`rownames<-\\\`( YOUR_ROWNAME_VEC )  <-- note the parenthese and backticks! \" ${NL}\
\" \" ${NL}\
\">> GZIP: verify files: for f in **/*.gz; do gunzip --test -v \\\$f ; done; \" ${NL}\
\">> LINE WRAP: wrap lines at 80 chars, preserving/ignoring word boundaries: fold -w 80 -s text.txt (omit -s to cut words) \" ${NL}\
\">> SHELL/BASH/ECHO: echo to STDERR instead of STDOUT: echoerr() { echo \\\"\\\$@\\\" 1>&2; }  usage: echoerr 'mystring' \" ${NL}\
\">> SHELL/BASH: Redirect stdout/stderr separately: CMD > out.txt 2> err.txt \" ${NL}\
\">> SHELL/BASH: Pipe both STDERR and STDOUT: CMD |& less  or the old way --> CMD 2>&1 (for bash < 4)\" ${NL}\
\">> SHELL/BASH: Modify variable: newV=\\\$(sed -e's/a/1/; s/b/2/; s/c/3/' <<< \\\$oldV) \" ${NL}\
\">> SHELL/BASH: Script run with ionice:  ionice -c3 -p\\\$\\\$ (top line of a /bin/sh script) \" ${NL}\
\">> SHELL/BASH: Rename files with parent directory in filename for f in DIRS*/file.whatever; do echo \\\$f \\\$(dirname \\\$f)/\\\$(dirname \\\$f).\\\$(basename \\\$f).whatever ; done \" ${NL}\
\">> SHELL/BASH: Rename files to NOT have the path in them at all: for fff in **/*.html ; do ggg=$(echo $fff | tr / _); mv $fff $ggg; done \" ${NL}\
\">> SHELL/BASH: Rename files to have unique names: for f in **/*fastqc.html; do /bin/cp \\\$f DESTINATION_DIR/\\\$(md5sum \\\$f | cut -d ' ' -f 1).\\\$(basename \\\$f); done \" ${NL}\
\">> SHELL/BASH: Rename files to a LIST of new names in a file: while read -u 9 SRC; do read -u 8 DEST; echo mv \\\"\\\$SRC\\\" \\\"\\\$DEST\\\"; done 9<<<\\\"\\\$(ls -1 * | grep -v NEW_FILENAME_LIST.TXT)\\\" 8< NEW_FILENAME_LIST.TXT  <-- note that NEW_FILENAME_LIST.TXT must be a SINGLE COLUMN of text in the same order as the files to rename. And the 'grep -v' part there is so that the filename list itself does not mess up the renaming. \" ${NL}\
\">> SHELL/BASH: Check to see if dir is empty if [[ \\\"\\\$(ls -A \\\$OUTDIR)\\\" ]]; then echo \\\"ERR: Output dir not empty!\\\"; exit 2; fi \" ${NL}\
\">> MD5 on EACH LINE OF A FILE (Perl) (note: WITHOUT the newline): cat YOURFILE | perl -e 'use Digest::MD5 qw(md5_hex); while(my \\\$line=<>){ chomp(\\\$line); print(md5_hex(\\\$line).qq{\n}); }'    \" ${NL}\
\">> MD5 verify: md5sum -c md5*.txt. Checksum must be 1st col, then 2 spaces, then filename. If checksum is 2nd: cat md5*.txt | awk '{print \\\$2\\\"  \\\"\\\$1}' | md5sum -c \" ${NL}\
\">> MD5 on multiple files: find . -type f -exec md5 {} \; > list.txt    \" ${NL}\
\">> HEX HEXDUMP: View bytes in hex form / hex editor: hexdump -C FILENAME   (or use colorized command-line viewer 'hexyl' on the Mac (brew install hexyl)) \" ${NL}\
\">> AWK: sum numbers in column 1 of a file: cat FILE | awk '{ sum+=\\\$1} END {print sum}'\" ${NL}\
\">> AWK: Get only FIRST line with a unique occurrence in column 1. Does not require sorting: cat FILE | awk -F'\\t' '!_[\\\$1]++' (assumes separator is tab) \" ${NL}\
\">> AWK FILTER based on numeric value (like select.pl): filter based on a number: cat test | awk '{ if (\\\$1 >= 900 && \\\$1 > 0) print; }' \" ${NL}\
\">> GIT: checkout file from other branch AND OVERWRITE LOCAL COPY:  echo 'overwriting local copy ' && git checkout OTHERBRANCH -- FILENAME \" ${NL}\
\">> GIT: change the 'upstream' of your branch to a REMOTE upstream: git branch YOURLOCALBRANCH --set-upstream-to origin/SOME_OTHER_BRANCH   <-- the 'origin' part seems necessary to make the upstream the remote \" ${NL}\
\">> GIT: do not download huge LFS files when git lfs is enabled: GIT_LFS_SKIP_SMUDGE=1 git clone YOUR_REPO \" ${NL}\
\">> GIT: only get the last 1 revision (faster): git clone --depth=1 https://your-site-here/something.git \" ${NL}\
\">> GIT: discard/revert ALL local changes TO ALL FILES: DANGER >> git reset --hard origin/master << DANGER \" ${NL}\
\">> GIT: discard/revert local changes to JUST ONE FILE: git checkout -- FILENAME_HERE \" ${NL}\
\">> GIT: fix an HTTP repo to SSH: git remote set-url origin git@github.com:RepoNameHere/ProjName.git \" ${NL}\
\">> GIT: see old version of file (example: ~4 = 4 revisons ago): git show HEAD~4:./some_file.txt \" ${NL}\
\">> GIT: delete a REMOTE branch: git push origin --delete BRANCHNAME (not delete, surprisingly) \" ${NL}\
\">> GIT: list files in a branch: git ls-tree -r -l BRANCHNAME \" ${NL}\
\">> GIT: what changed between branches?: git diff --summary BRANCH1 BRANCH2 \" ${NL}\
\">> GIT: GUI and 'when was a branch made from master': gitk --all --select-commit=\\\$(git merge-base YOURBRANCH master)  \" ${NL}\
\">> GIT: when branch was last used (MINIMAL): for BRANCH in \\\$(git branch -r | grep -v 'HEAD'); do echo -e \\\$(git show --format='%ci %cr' \\\$BRANCH | head -n 1) \\\\\\\\t\\\$BRANCH; done | sort -r \" ${NL}\
\">> GIT: when branch was last used AND last commit (fancy): git for-each-ref --sort=committerdate refs/heads/ --format='%(HEAD) %(color:yellow)%(refname:short)%(color:reset) - %(color:red)%(objectname:short)%(color:reset) - %(contents:subject) - %(authorname) (%(color:green)%(committerdate:relative)%(color:reset))' \" ${NL}\
\">> TERM: Get terminal width/height: tput cols  or  tput lines \" ${NL}\
\">> BACKUPS: Check for changed files of a certain name: grep -E '>f.' /it/backup/log/*.log | grep YOURNAME \" ${NL}\
\">> UNIX/FILE: Add filename to top of (copy of) files. for f in FILES*; do echo \\\$f | cat - $f > NEW_\\\$f ; done     ...or if you will later paste/join those: for f in SPLIT*.diff; do echo \\\$f | cat - \\\$f | table-no-ragged.py - > NEW_\\\$f; done \" ${NL}\
\">> UNIX: SYMLINKS: convert RELATIVE symlinks to ABSOLUTE PATHS: for fff in *; do FULL=\\\$(readlink -f \\\$fff); ln -sf \\\$FULL \\\$fff ; done \" ${NL}\
\">> UNIX: SYMLINKS: 1) double-dereference symlinks, showing their final targets: find -L . -type f -exec readlink -f {} \\\; \" ${NL}\
\">> UNIX: SYMLINKS: 2) double-dereference symlinks, showing their final targets: for f in * ; do echo -e \\\$f\\\"\\t\\\"\\\$(readlink -f \\\$f); done   \" ${NL}\
\">> UNIX: SYMLINKS: Just delete ALL symlinks: find DIRNAME/ -type l -delete \" ${NL}\
\">> UNIX: SYMLINKS: print orphaned/broken symlinks: find . -type l -exec sh -c \\\"file -b {} | grep -q ^broken\\\" \; -print \" ${NL}\
\">> UNIX: SYMLINKS: set up symlinks from TimeForScience: ln -sfn ~/TimeForScience/Config/Alex_Williams/.??* ~/ \" ${NL}\
\">> UNIX: SYMLINKS: executables: for f in \\\$(find PATH -maxdepth 1 -perm -111 -type f); do ln -s \\\$f ./; done \" ${NL}\
\">> UNIX: total file size for files with a certain extension (Here, jpg): find . -type f -iname '*.jpg' -print0 | du -ch --files0-from=- \" ${NL}\
\">> UNIX: list files w/modified time MORE THAN one week ago: find . -mtime +7 \" ${NL}\
\">> UNIX: list files w/modified time LESS THAN one week ago: find . -mtime -7 \" ${NL}\
\">> UNIX: list files w/modified time two days ago: find . -mtime 2 \" ${NL}\
\">> UNIX: list files w/modified time between 6 and 9 minutes ago: find . -mmin +5 -mmin -10 \" ${NL}\
\">> UNIX: list ONLY dot files, no .. or up a directory: ls -l .??* \" ${NL}\
\">> UNIX: upgrade: sudo aptitude update && sudo aptitude safe-upgrade <-- more assertive than apt-get upgrade.\" ${NL}\
\">> UNIX: IO nice (low-priority): ionice -c2 -n7 -pPROCID <-- -n7: lowest non-idle priority. PROCID is the PID.\" ${NL}\
\">> UNIX: IO nice (lowest-priority): ionice -c3 -pPROCID  <-- -c3: IDLE priority; doesn't slow anyone else down.\" ${NL}\
\">> UNIX: IO nice for a user \\\$THEUSER: SSS=\\\$(ps -fu \\\$THEUSER | perl -pe 's/[ ]+/\t/g' | cut -f 2 | tail -n +2); for pid in \\\$SSS ; do echo 'PID' \\\$pid; sudo ionice -c3 -p \\\$pid ; sudo renice +10 -p \\\$pid; done\" ${NL}\
\">> UNIX: Find zombie processes: ps aux | awk '{ print \\\$8 \\\" \\\" \\\$2 }' | grep -w Z \" ${NL}\
\">> UNIX: Check Linux version: cat /etc/*-release \" ${NL}\
\">> UNIX: Set system time on Ubuntu: sudo ntpdate-debian \" ${NL}\
\">> RSYNC transfer files: rsync --dry-run -R -havz --progress --stats --bwlimit=999999 LOCALFILES USER@REMOTE.COM:/path/to/  \" ${NL}\
\">> UNIX: Password FTP command line Xfer: wget -r ftp://USERNAME:password@ftp.some.site.com/Somefiles \" ${NL}\
\">> UNIX/WGET/TRICKLE: Rate limit any command to 500kbps (-d = down, -u = up): sudo trickle -d 500 -u 500 ncftp 'your_ftp_site_here' \" ${NL}\
\">> UNIX: See why Ubuntu wants to restart:  cat /var/run/reboot-required.pkgs \" ${NL}\
\">> UNIX/TOP/USAGE/HTOP: CPU usage by user: top -b -n 1 -u \\\$USER | awk 'NR>7 { sum += \\\$9; } END { print sum; }' \" ${NL}\
\">> UNIX SCREEN: did your arrow keys stop working in 'less' within 'screen'? Detach the screen (modifier+d), then run 'reset' on the command line in the outer shell. \" ${NL}\
\">> UNIX SCREEN: full screen a tiny window: modifier + F (capital F) for 'fill'. \" ${NL}\
\">> UNIX GREP: filter files based on presence of text: mkdir YES NO; for f in *.txt; do if [[ \\\"\\\$(grep 'YOUR_STRING_HERE' \\\$f | wc -l)\\\" -ne \\\"0\\\" ]]; then mv \\\$f yes/; else mv \\\$f no/; fi ; done \" ${NL}\
\">> UNIX GREP: find text in a file VERBATIM, like join: grep -w -f KEYFILE.txt search_in_file.txt  (remove the '-w' to allow PARTIAL matches as well. You can use '-E' to allow regular expressions in the file too!)\" ${NL}\
\">> UNIX GREP Count occurrences of a match per line: cat FILE | grep -o -n SEARCHTERM | cut -d : -f 1 | uniq -c \" ${NL}\
\">> BSUB change queue that a job is in: bswitch LONGQUEUE <YOUR_JOB_ID_HERE> \" ${NL}\
\">> QSUB/QUEUE/PBS submit job: echo 'echo \\\"hello I am a test job\\\"' | qsub -q Bio -W group_list=YOURQUEUE ; sleep 10; cat STDIN*; \" ${NL}\
\">> QSUB/QUEUE/PBS: Delete all your jobs one by one: for j in \\\$${PAREN_OPEN}qstat -a | grep 'YOURNAME' | cut -d '.' -f 1); do echo \\\"qdel \\\$j...\\\"; qdel \\\$j ; done \" ${NL}\
\">> QSUB/QUEUE/PBS: restart torque: sudo service pbs_sched stop ; sudo service pbs_mom stop ; sudo service pbs_server stop ; sudo /bin/rm /var/lock/subsys/pbs_server ; sudo service pbs_sched start ; sudo service pbs_mom start ; sudo service pbs_server start ; qstat \" ${NL}\
\">> QSUB/QUEUE/PBS: info on the queue: qstat -Qf or qstat -B more details \" ${NL}\
\">> QSUB/QUEUE/PBS: qrun MULTIPLE jobs in a range: for f in \\\$(seq 119905 119919); do sudo \\\$(which qrun) \\\$f; done \" ${NL}\
\">> QSUB/QUEUE/PBS: kill all YOUR jobs: qselect -u \\\$USER | xargs qdel ; \" ${NL}\
\">> QSUB/QUEUE/PBS: see available nodes / available queue resources:  pbsnodes -a   (gives a summary)   or   pbsnodes -a -v (per 'socket')  or  qstat -Qf (per-queue amounts \" ${NL}\
\">> UNIX/DPKG/APT-GET: dpkg/apt-get woes? Try manually editing /var/lib/dpkg/info/YOURPACKAGE . Be careful! \" ${NL}\
\">> UNIX/DPKG/APT-GET: Check the version of an apt-get installed package:   dpkg -s <packagename>  OR   dpkg -l | grep -i <search_string> \" ${NL}\
\">> UNIX/YUM/RPM install: (this NEVER works, but): rpm -Uvh your.rpm . Does NOT handle dependencies.\" ${NL}\
\">> YUM list installed packages: yum list installed \\\"*perl*\\\"  <-- stars are important!    \" ${NL}\
\">> UNIX/APTITUTDE: sudo aptitude update && sudo aptitude safe-upgrade <-- more assertive than apt-get upgrade.\" ${NL}\
\">> UNIX/APT-GET: upgrade only EXISTING packages matching wildcard pattern: apt-get install --only-upgrade 'r-cran*' \" ${NL}\
\">> UNIX/APT-GET: Fix 'NO_PUBKEY *SOMEKEY*' in APT: gpg --keyserver subkeys.pgp.net --recv *SOMEKEY* ; gpg --export --armor *SOMEKEY* | sudo apt-key add - \" ${NL}\
\">> UNIX SSH/SHELL/LOGIN to a 'fresh' shell without loading bashrc or bash_profile: ssh -t user@server bash --norc --noprofile \" ${NL}\
\">> UNIX SSH Passphraseless: Client: ssh-keygen -t rsa ; Append client ~/.ssh/id_rsa.pub   to server ~/.ssh/authorized_keys \" ${NL}\
\" \" ${NL}\
\">> ZIP: Zip a folder: zip -r ARCHIVENAME FOLDER \" ${NL}\
\" \" ${NL}\
\">> GNU MAKE with a bash loop (5 lines, look for text 'MAKELOOP'): \" ${NL}\
\">> MAKELOOP1: looped: INFILE.txt                   \" ${NL}\
\">> MAKELOOP2:         while read -r X; do     \\   \" ${NL}\
\">> MAKELOOP3:                 echo \\\$\\\$X; \\   \" ${NL}\
\">> MAKELOOP4:         done < INFILE.txt;      \\   \" ${NL}\
\">> MAKELOOP5:         true                         \" ${NL}\
\">> MAKEFILE: set variables in rule:   \\\$(eval TMP := \\\$(shell mktemp -d))  and then try echo \\\$(TMP) \" ${NL}\
\">> SHELL/BASH put a command into a variable with quotes and then execute it:  DEFINE: MYCMD=(perl -ne 'print 1;')   THEN:  gzcat FILE | \\\"{MYCMD[@]}\\\" \" ${NL}\
\">> SHELL/BASH startup a 'fresh' shell with NO user configuration / clean startup / no .bashrc / no init:  env -i bash --norc --noprofile      \" ${NL}\
\">> SHELL/BASH script header (2 lines): #!/bin/bash __NEWLINE__ set -euo -o pipefail; shopt -s nullglob; shopt -s globstar; set -o xtrace; \" ${NL}\
\">> SHELL/BASH in MAKEFILE: In a Make rule, you can use a bash loop like so, with THREE slashes before a quote and SLASH-DOLLAR-DOLLAR instead of a dollar sign to access BASH variables. Example:  bash -c ${DQ}for fff in */*; do echo -e ${BS}${BS}${BS}${DQ}${BS}${DLR}${DLR}fff${BS}${BS}${BS}${DQ}; done; echo -e ${BS}${BS}${BS}${DQ}This goes in a makefile.${BS}${BS}${BS}${DQ}; ${DQ} \" ${NL}\
\">> SHELL/BASH: Literal tab: \\\$'\\t' (example: join -t \$'\\t' to join on tabs) or \\\$(echo -en '\\t') . In MAKE: printf '\\t' \" ${NL}\
\">> SHELL/BASH: Get directory of this script (fails if last item is a symlink): DIR_OF_SCRIPT=\\\"\\\$( cd \\\"\\\$(dirname \\\"\\\${BASH_SOURCE[0]}\\\" )\\\" && pwd )\\\" \" ${NL}\
\">> SHELL/BASH: Foreach/rename: for f in \\\$${PAREN_OPEN}ls); do echo \\\$f will become \\\$${BRACKET_OPEN}f/.txt/.newending} ; done \" ${NL}\
\">> SHELL/BASH: redirect STDERR & STDOUT both to console and to a file: THECMD 2>&1 | tee --append LOGFILE\" ${NL}\
\">> SHELL/BASH: See a function definition: type FUNCTIONNAME \" ${NL}\
\">> SHELL/BASH: Change tab width in bash:  setterm -regtabs 16 (16 = huge!) \" ${NL}\
\">> SHELL/BASH: Expand tabs/tab width: something | expand -t 32 \" ${NL}\
\">> PERL: redirect STDERR and STDOUT in backticks: my \\\$stderr_and_out = \\\`commandhere 2>&1\\\`; my \\\$exitCode = \\\$?; \" ${NL}\
\" \" ${NL}\
\">> BIOINF / GTF: Sort a GTF file:  LC_ALL=\\\"C\\\" sort -k 1,1 -k 4,4n YOUR.GTF > SORTED.GTF \" ${NL}\
\">> BIOINF / GTF: Load a GTF file into R:  require(rtracklayer); require(GenomicRanges); granges_from_gtf <- rtracklayer::import.gff('~/THE_GTF.GZ')  \" ${NL}\
\" \" ${NL}\
\">> Gnu parallel: works like xargs, but works with files with spaces, by default. \" ${NL}\
\">> XARGS/FIND multiple commands: find . -name SOMEFILE -print0 | xargs -0 -I {} sh -c \\\"echo {}; thing {} | piped here | wc -l ; \\\"  \" ${NL}\
\">> XARGS/FIND: bzip all the bed/diff/count files that you can find: find . -type f \( -iname \\\"*.bed\\\" -o -iname \\\"*_tracking\\\" -o -iname \\\"*.diff\\\" -o -iname \\\"*.moa\\\" -o -iname \\\"*.fasta\\\" -o -iname \\\".fa\\\" -o -iname \\\"*.bed.count\\\" \) -print0 | xargs -0 bzip2 \" ${NL}\
\">> CHMOD Make files readable, directories r+x (print0/-0 makes filenames with spaces work): sudo chmod -R a+r ./ ; sudo find ./ -type d -print0 | sudo xargs -0 chmod a+x   (this is the command 'sudoshowoff')\" ${NL}\
\">> GNU FIND and DELETE a file (dangerous): find . -name SOMEFILE -delete \" ${NL}\
\">> PERL: fast sort with ONE header line: cat FILE | perl -e 'print scalar (<>); print sort <>' > OUTFILE \" ${NL}\
\">> PERL: REGEXP multi-line search/replace: perl -00pe 's{thing1}{thing2}gxms' THE_FILE  <-- s lets '.' match newlines\; m makes ^ and \\\$ work \" ${NL}\
\">> PERL: replace IN PLACE in a file, with backups for \\\$file in FILES; do perl -p -i.bak -e 's/STRING_TO_REPLACE/NEW_STRING/g' \\\$file; done  \" ${NL}\
\">> PERL: or WEB: Chrome web form non-breaking space (ASCII 160) is [\\xA0] (or 'use feature qw(unicode_strings);') \" ${NL}\
\">> PERL: CPAN invocation: sudo perl -MCPAN -e shell \" ${NL}\
\">> PERL: CPAN upgrade all WITHOUT prompting: PERL_MM_USE_DEFAULT=1 && sudo perl -MCPAN -e shell >> then o conf build_requires_install_policy yes  ; o conf prerequisites_policy 'follow'  ; o conf commit ;  upgrade /(.\\*)/\\\" \" ${NL}\
\">> PERL: Backreferences/does something show up twice on a line: perl -n -e 'print ((\\\$_ =~ /\b(Something\d+)\s.\g1/) ? qq{match: \\\$1\\n} : qq{Nope\\n});' \" ${NL}\
\">> EMACS: insert newline in search-and-replace:  Ctrl-Q Ctrl-J \" ${NL}\
\">> EMACS: install new packages: list-packages \" ${NL}\
\">> EMACS: show variable: describe-variable \" ${NL}\
\" \" ${NL}\
\">> Convert SAM to BAM with QPLZ:  for SSS in **/*.sam; do qplz --background \\\"samtools view -bS \\\$SSS > \\\${SSS/.sam}.bam\\\" ; done \" ${NL}\
\">> BIOINF FASTA remove linebreaks from sequence (make one-line fasta sequences): cat file.fasta | awk '!/^>/{printf \\\"%s\\\", \\\$0; n=\\\"\\n\\\"} /^>/{print n \\\$0; n=\\\"\\\"} END {printf\\\"%s\\\",n}' > out.fa \" ${NL}\
\">> BIOINF SEQ: fastq2fasta (fq2fa, fastq -> fasta): zcat FQ.fq.gz | awk '{if(NR%4==1) {printf(\\\">%s\n\\\",substr(\\\$0,2));} else if(NR%4==2) print;}' > FASTA.fa \" ${NL}\
\">> BIOINF SEQ: bcl2fastq: NCPU=4; bcl2fastq --fastq-compression-level 5 --barcode-mismatches 1 --no-lane-splitting -r $NCPU -d $NCPU -p $NCPU -w $NCPU --sample-sheet 'THIS_MUST_BE_VALID_NOT_MAC_FORMAT.csv'  --runfolder-dir=WEIRDLY_NAMED_160_NB01415_ABCDQBXX   (output goes to Data/Intensities/BaseCalls/*.fastq.gz) \" ${NL}\
\">> BIOINF FASTQ/FASTA subsample 500 reads randomly. Use -s1234 (random seed) so you can get the same reads in paired-end situations: seqtk sample -s1234 read1.fq.gz 500 | gzip > sub1.fq.gz \" ${NL}\
\">> BIOINF FASTQ: sort by read ID:  zcat YOUR.fq.gz | paste - - - - | sort -k1,1g -t \\\" \\\" | tr \\\"\\t\\\" \\\"\\n\\\" | gzip > SORTED.fq.gz (or use 'fastq_sort_by_read_name.sh') \" ${NL}\
\">> BIOINF RNASEQ: SAM --> BAM:  samtools view -bS in.sam > out.bam \" ${NL}\
\">> BIOINF RNASEQ: BAM --> SAM:  samtools view -h  in.bam > out.sam \" ${NL}\
\">> BIOINF RNASEQ: samtools view first read of pair only:  samtools view -f  64 file.bam \" ${NL}\
\">> BIOINF RNASEQ: samtools view second read of pair only: samtools view -f 128 file.bam \" ${NL}\
\">> BIOINF RNASEQ: sort SAM and setting the 'sorted' flag:  java -Xmx2g  -jar SortSam.jar INPUT=in.sam SORT_ORDER=coordinate OUTPUT=out_sorted.sam \" ${NL}\
\">> BIOINF RNASEQ: View BAM header: samtools view -H  in.bam \" ${NL}\
\">> BIOINF RNASEQ: Merge BAM files in subdirectories: for f in * ; do samtools merge \\\${f}_merged.bam \\\$f/*.bam; done \" ${NL}\
\">> BIOINF RNASEQ: arbitrary text filtering in Perl on a BAM file: samtools view -h in.bam | perl -ne 'if (m/^@/) {print;} else { print if m/YOURCONDITIONHERE/; }' | samtools view -bS > filtered.bam  \" ${NL}\
\">> BIOINF RNASEQ: remove non-primary and non-aligned reads: samtools view -b -F 0x104 in.bam > mapped_primary.bam \" ${NL}\
\">> BIOINF RNASEQ: count primary (0x100) mapped (0x4) reads: samtools view -c -F 0x104 in.bam > COUNT.txt\" ${NL}\
\">> BIOINF RNASEQ: Count frequencies of first 5 bases of a SAM file: cut -f 10 theFile.sam | cut -c 1-5 | sort | uniq -c \" ${NL}\
\">> BIOINF RNASEQ: TOPHAT/rename subdirectories TEST (change 'echo' to 'mv' for the real one): for f in *; do echo \\\${f}/accepted_hits.bam \\\${f}/accepted_hits_\\\${f}.bam ; done \" ${NL}\
\">> BIOINF RNASEQ: Truncate FASTQ file to length 19 without fastx-trimmer: awk 'NR % 2 == 0 { \\\$0=substr(\\\$0,1,19)} {print}' \" ${NL}\
\">> BIOINF SRA: Obtain SRA sequence from NCBI: prefetch --verbose SRR__whateverID__ \" ${NL}\
\">> BIOINF SRA->FASTQ: fastq-dump --gzip SRR1234.sra    (<-- creates new file 'SRR1234.fastq.gz') \" ${NL}\
\">> MINION LONG READ SEQ: FAST5 to FASTQ: Make a single FASTQ out of all FAST5s in each of the 'barcode' subdirectories (assumes the file structure is: minion/barcode01/batch9988/file.fast5): for bar in barcode*; do final=ToFQ.\\\$bar.final.fq.gz; /bin/rm -f \\\$final; for f in \\\${bar}/*/*.fast5; do echo \\\"Handling \\\$f\\\"; poretools fastq \\\$f | gzip >> \\\$final; done; done \" ${NL}\
\" \" ${NL}\
\">> BIOINF BLAST: Extract all info (sequence names and FASTA sequence) from a database: blastdbcmd -entry all -db YOUR_DATABASE_PREFIX \" ${NL}\
\">> BIOINF BLAST: DNA pair-wise similarity for all sequences in a fasta file:   makeblastdb -in REF.fa -dbtype nucl  &&  blastn -outfmt 6 -db REF.fa -query REF.fa -title 'BLAST index' -out results.out \" ${NL}\
\">> BIOINF BLAST: MakeblastDB on COMPRESSED gzip input fasta: gunzip -c GENOME.fasta.gz | makeblastdb -in - -title 'OUTPUTNAME' -dbtype nucl -out OUTFILEPREFIX  \" ${NL}\
\">> BIOINF BLAST: extract DATABASE sequences back to FASTA: In the directory with database files starting with the prefix 'nt_your_prefix_whatever', blastdbcmd -db nt_your_prefix_whatever -entry all -out - | gzip > all_sequences.fasta  \" ${NL}\
\">> BIOINF BLAST: if you have PROTEINS, see where they are in NUCLEOTIDE space using tblastn. Also use a custom output format that SHOWS the alignment in a table: tblastn -query myproteins.faa -subject refgenome.fasta -outfmt \\\"6 qacc sacc btop\\\" > OUTPUT_with_alignment.blast.out.txt \" ${NL}\
\">> BIOINF BLAST: if you generate a blast query with -outfmt 11, you can use 'blast_formatter' to reformat it into other output types! So:   blast [...] -outfmt 11 -out BLASTOUT.asn     and then:    blast_formatter -archive BLASTOUT.asn -outfmt \\\"7 qacc sacc evalue qstart qend sstart send \\\"  \" ${NL}\
\">> BIOINF BLAST: the ultimate custom formatting for thorough individuals: blastn -query QUERY.fa -subject REFERENCE.fa -outfmt \\\"7 qseqid qlen qstart qend sseqid slen sstart send qseq sseq evalue bitscore score length pident nident mismatch gaps btop\\\" > outfmt_custom.blast.txt  \" ${NL}\
\">> BIOINF DNA reverse-complement: perl -e '\\\$x = qq{AAAA_SEQUENCE_GGGG_TT_CC}; \\\$_ = scalar(reverse(\\\$x)); tr/ACGT/TGCA/; print \\\$_;' \" ${NL}\
\" \" ${NL}\
\">> UNIX APACHE error log: sudo less -S /var/log/apache2/error.log \" ${NL}\
\">> MAC: DNS woes: sudo dscacheutil -flushcache \" ${NL}\
\">> MAC: Dictionary: /usr/share/dict/words \" ${NL}\
\">> MAC: why isn't the screensaver working: pmset -g (see 'sleep' in there), then pmset -g assertions \" ${NL}\
\">> MAC: Image type convert: mkdir -p PNGS_TO_JPEG; sips -s format jpeg *.png --out PNGS_TO_JPEG \" ${NL}\
\">> GITHUB solve 'Your push would publish a private email address': git config --global user.email 'YOURGITHUB_USERNAME_GOES_HERE@users.noreply.github.com'; git commit --amend --reset-author; git push ; (and make sure you don't have a .git/config that overrides this setting)\" ${NL}\
\">> UNIX COPROC: coproc: re-run a command every 19 seconds: for i in {1..50} ; do coproc { ls >> myfile.tmp ; } ; sleep 19; kill \\\$COPROC_PID ; sleep 2; done \" ${NL}\
\">> LINES: RANDOM subset (0.5 = 50%, 0.1 = 10%, etc):  perl -ne 'print if (rand() < 0.5);' theFile.txt \" ${NL}\
\">> LINES: REPEATABLE RANDOM subset: perl -e 'srand(123456); while(<>){ print if (rand() < 0.5);}' theFile.txt \" ${NL}\
\">> LINES: Semi-random FASTA records (2 lines at a time): perl -e 'my \\\$total=0; my \\\$MAX=3; srand(); while(<>){ if (rand()<0.01) { print \\\$_; my \\\$nextLine=<>; print \\\$nextLine; \\\$total++; exit(0) if (\\\$total>=\\\$MAX); } }' \" ${NL}\
\">> LINES: Range from N to M, inclusive (starts at 1):  sed -n N,Mp INPUTFILE  or  for a HUGE file: sed -n '(N+1)q;N,Mp' <-- quit on line (N+1) \" ${NL}\
\">> LINES: Every Nth line, starting with line Y (starts at 1, not 0): awk 'NR%X==Y' FILE. So getting line 1,3,5,7,9 is awk 'NR%2==1'. FASTQ example: sequences only is awk 'NR%4==2'\" ${NL}\
\">> LINES/AWK: Count num columns in file: awk -F '\t' '{print NF}' \" ${NL}\
\">> LINES based on perl expr: perl -e '\\\$n = 0; while(<>) { if (\\\$n%2 == 0) { print \\\$_; }; \\\$n++; }' \" ${NL}\
\">> LINES Count chars on each line: cat FILENAME | awk '{print length(\\\$0)}' \" ${NL}\
\">> UNIX/LINES/AWK re-order columns: cat FILE | awk 'BEGIN {OFS = \\\"\t\\\"}; {print \\\$1,\\\$4,\\\$2,\\\$11}' \" ${NL}\
\">> SQL/POSTGRES Amazon Redshift show errors: select d.*,e.* from stl_load_errors e, stl_loaderror_detail d where d.query = e.query AND d.query = pg_last_copy_id() order by starttime desc; \" ${NL}\
\">> SQL/POSTGRES list databases: SELECT datname FROM pg_database WHERE datistemplate=FALSE;   \" ${NL}\
\">> SQL/POSTGRES list databases, schemas and tables: SELECT table_schema,table_name  FROM information_schema.tables  ORDER BY table_schema,table_name;  \" ${NL}\
\">> SQL/POSTGRES count records grouped by month and year:   SELECT EXTRACT(YEAR from the_date) as YYYY, EXTRACT(MONTH from the_date) as MM, count(*) as count FROM YOUR_DATA WHERE 1=1 group by EXTRACT(MONTH from date), EXTRACT(YEAR from date) ORDER BY YYYY asc, MM asc; \" ${NL}\
\">> PYTHON/PANDAS sort pandas data frame in place by absolute value: DF.reindex(DF['your_value'].abs().sort_values(ascending=False).index)   \" ${NL}\
\">> JUPYTER/PYTHON prevent auto-closing brackets/braces/parens: from notebook.services.config import ConfigManager  <NEWLINE>  c = ConfigManager()   <NEWLINE>      c.update('notebook', {'CodeCell': {'cm_config': {'autoCloseBrackets': False}}})   \" ${NL}\
\">> JUPYTER/PYTHON prevent scrolling regions in plots. Put this in its own cell: %%javascript  <NEWLINE>   IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }   \" ${NL}\
\">> JUPYTER/PYTHON/MATPLOTLIB/SNS change figure size plt.rcParams['figure.figsize'] = (WIDTH, HEIGHT)   and   plt.rcParams['figure.dpi'] = 250    \" ${NL}\
\">> Z SOFTWARE to remember: Bioinformatics: UGENE will do Clustal/BLAST/Etc locally, and visualize sequences / FASTAS. MAUVE is a similar aligner that we used previously for viral genomes.  IGV is a local genome browser. TreeView and Cluster 3 will cluster.  General: GLANCES is fancier top/htop system activity monitor. HEXYL is a colorized Mac command line hex editor (brew install hexyl).\" ${NL}\
"
